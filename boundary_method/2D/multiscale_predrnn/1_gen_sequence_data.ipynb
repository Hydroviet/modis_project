{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "from shutil import copytree, ignore_patterns, unpack_archive\n",
    "sys.path.append('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modis_utils.misc import cache_data, restore_data\n",
    "from modis_utils.image_processing import get_pixel_weights\n",
    "from modis_utils.misc import restore_data, cache_data, normalize_data\n",
    "from modis_utils.misc import get_data_paths, get_target_paths, get_data_from_data_file, get_target_from_target_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 16\n",
    "\n",
    "preprocess_data_dir = '../preprocessed_data'\n",
    "pixel_weights_dir = '../pixel_weights'\n",
    "\n",
    "water_threshold = (0.1 + 0.2001)/1.2001\n",
    "timesteps = 48\n",
    "n_data_per_year = 46\n",
    "n_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_targets_pw(list_filenames, pws, idx_data_type, n_out):\n",
    "    list_filenames_data_type = list_filenames[idx_data_type[0]:idx_data_type[1] + n_out - 1]\n",
    "    pws_data_type = pws[idx_data_type[0]:idx_data_type[1] + n_out - 1]\n",
    "    list_inputs = []\n",
    "    list_targets = []\n",
    "    list_pw_inputs = []\n",
    "    list_pw_targets = []\n",
    "    for i in range(timesteps, len(list_filenames_data_type) - n_out + 1):\n",
    "        list_inputs.append(list_filenames_data_type[i - timesteps : i])\n",
    "        list_targets.append(list_filenames_data_type[i : i + n_out])\n",
    "        list_pw_inputs.append(pws_data_type[i - timesteps : i])\n",
    "        list_pw_targets.append(pws_data_type[i : i + n_out])\n",
    "    return list_inputs, list_targets, list_pw_inputs, list_pw_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_file(data_file_dir, list_filenames, pws, idx, n_out):\n",
    "    if not os.path.exists(data_file_dir):\n",
    "        os.makedirs(data_file_dir)\n",
    "\n",
    "    return_paths = {}\n",
    "    for data_type in ('train', 'val', 'test'):\n",
    "        input_filename = os.path.join(data_file_dir, '{}_input.csv'.format(data_type))\n",
    "        target_filename = os.path.join(data_file_dir, '{}_target.csv'.format(data_type))\n",
    "        pw_input_filename = os.path.join(data_file_dir, '{}_pw_input.csv'.format(data_type))\n",
    "        pw_target_filename = os.path.join(data_file_dir, '{}_pw_target.csv'.format(data_type))\n",
    "\n",
    "        list_inputs, list_targets, list_pw_inputs, list_pw_targets = \\\n",
    "            get_inputs_targets_pw(list_filenames, pws, idx[data_type], n_out)\n",
    "\n",
    "        input_f = open(input_filename, 'w')\n",
    "        input_writer = csv.writer(input_f)\n",
    "        target_f = open(target_filename, 'w')\n",
    "        target_writer = csv.writer(target_f)\n",
    "        pw_input_f = open(pw_input_filename, 'w')\n",
    "        pw_input_writer = csv.writer(pw_input_f)\n",
    "        pw_target_f = open(pw_target_filename, 'w')\n",
    "        pw_target_writer = csv.writer(pw_target_f)\n",
    "\n",
    "        for row in list_inputs:\n",
    "            input_writer.writerow(row)\n",
    "        input_f.close()\n",
    "        for row in list_targets:\n",
    "            target_writer.writerow(row)\n",
    "        target_f.close()\n",
    "        for row in list_pw_inputs:\n",
    "            pw_input_writer.writerow(row)\n",
    "        pw_input_f.close()\n",
    "        for row in list_pw_targets:\n",
    "            pw_target_writer.writerow(row)\n",
    "        pw_target_f.close()\n",
    "\n",
    "        return_paths[data_type] = {'input': input_filename,\n",
    "                                   'target': target_filename,\n",
    "                                   'pw_input': pw_input_filename,\n",
    "                                   'pw_target': pw_target_filename}\n",
    "    return return_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_data_1(sequence_data_type_dir, data_type, data_file_paths,\n",
    "                           water_threshold, start_idx, end_idx):\n",
    "    data_type_file_paths = data_file_paths[data_type]\n",
    "    input_file = data_type_file_paths['input']\n",
    "    target_file = data_type_file_paths['target']\n",
    "    pw_target_file = data_type_file_paths['pw_target']\n",
    "    for i in range(start_idx, end_idx):\n",
    "        inputs = get_data_from_data_file(input_file, i)\n",
    "        target = get_data_from_data_file(target_file, i)\n",
    "        input_pixel_weights = np.array(list(map(lambda x: get_pixel_weights(x, water_threshold), inputs)))\n",
    "        target_pixel_weights = get_data_from_data_file(pw_target_file, i)\n",
    "        cache_data((inputs, target, input_pixel_weights, target_pixel_weights),\n",
    "                   os.path.join(sequence_data_type_dir, '{}.dat'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_data(n_cores, sequence_data_dir, data_file_paths, n_data, water_threshold):\n",
    "    for data_type in ('train', 'val', 'test'):\n",
    "        sequence_data_type_dir = os.path.join(sequence_data_dir, data_type)\n",
    "        if not os.path.exists(sequence_data_type_dir):\n",
    "            os.makedirs(sequence_data_type_dir)\n",
    "        processes = []\n",
    "        n = n_data[data_type]\n",
    "        m = n // n_cores\n",
    "        r = n % n_cores\n",
    "        start_idx = 0\n",
    "        for i in range(n_cores):\n",
    "            q = m + 1 if i < r else m\n",
    "            end_idx = start_idx + q\n",
    "            p = mp.Process(target=create_sequence_data_1, \n",
    "                           args=(sequence_data_type_dir, data_type, data_file_paths,\n",
    "                                 water_threshold, start_idx, end_idx))\n",
    "            processes.append(p)\n",
    "            start_idx = end_idx\n",
    "\n",
    "        for p in processes:\n",
    "            p.start()\n",
    "        for p in processes:\n",
    "            p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 1\n",
    "sequence_data_dir = 'data/sequence_data'\n",
    "if not os.path.exists(sequence_data_dir):\n",
    "    os.makedirs(sequence_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_filenames = sorted(os.listdir(preprocess_data_dir))\n",
    "pws = [os.path.join(pixel_weights_dir, filename) for filename in list_filenames]\n",
    "list_filenames = [os.path.join(preprocess_data_dir, filename) for filename in list_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = n_data_per_year\n",
    "n_test = n_data_per_year*2 - n_out + 1\n",
    "n_train = len(list_filenames) - 3*n_data_per_year - timesteps\n",
    "\n",
    "n_data = {'train': n_train, 'val': n_val, 'test': n_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = (0, n_train + timesteps)\n",
    "val_id = (n_train, n_train + n_val + timesteps)\n",
    "test_id = (n_train + n_val, len(list_filenames) - n_out + 1)\n",
    "idx = {}\n",
    "idx['train'] = train_id\n",
    "idx['val'] = val_id\n",
    "idx['test'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_dir = os.path.join(sequence_data_dir, 'data_file')\n",
    "if not os.path.exists(data_file_dir):\n",
    "    os.makedirs(data_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'input': 'data/sequence_data/data_file/train_input.csv',\n",
       "  'target': 'data/sequence_data/data_file/train_target.csv',\n",
       "  'pw_input': 'data/sequence_data/data_file/train_pw_input.csv',\n",
       "  'pw_target': 'data/sequence_data/data_file/train_pw_target.csv'},\n",
       " 'val': {'input': 'data/sequence_data/data_file/val_input.csv',\n",
       "  'target': 'data/sequence_data/data_file/val_target.csv',\n",
       "  'pw_input': 'data/sequence_data/data_file/val_pw_input.csv',\n",
       "  'pw_target': 'data/sequence_data/data_file/val_pw_target.csv'},\n",
       " 'test': {'input': 'data/sequence_data/data_file/test_input.csv',\n",
       "  'target': 'data/sequence_data/data_file/test_target.csv',\n",
       "  'pw_input': 'data/sequence_data/data_file/test_pw_input.csv',\n",
       "  'pw_target': 'data/sequence_data/data_file/test_pw_target.csv'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_paths = create_data_file(data_file_dir, list_filenames, pws, idx, n_out)\n",
    "data_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sequence_data(n_cores, sequence_data_dir, data_file_paths, n_data, water_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
