{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modis_utils.misc import restore_data, cache_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tfrecord(input_files, output_file, resize=None):\n",
    "    \"\"\"Converts a file to TFRecords.\"\"\"\n",
    "    print('Generating %s' % output_file)\n",
    "    with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "        for input_file in tqdm(input_files):\n",
    "            inputs, labels, inputs_pw, labels_pw = restore_data(input_file)\n",
    "            if resize:\n",
    "                inputs = inputs[:, 1:, 1:]\n",
    "                labels = labels[:, 1:, 1:]\n",
    "                inputs_pw = inputs_pw[:, 1:, 1:]\n",
    "                labels_pw = labels_pw[:, 1:, 1:]\n",
    "            example = tf.train.Example(features=tf.train.Features(\n",
    "                feature={\n",
    "                    'inputs': _float_feature(inputs.flatten().tolist()),\n",
    "                    'labels': _float_feature(labels.flatten().tolist()),\n",
    "                    'inputs_pw': _float_feature(inputs_pw.flatten().tolist()),\n",
    "                    'labels_pw': _float_feature(labels_pw.flatten().tolist())\n",
    "                }))\n",
    "            record_writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tfrecord_patch(input_files, output_file):\n",
    "    \"\"\"Converts a file to TFRecords.\"\"\"\n",
    "    print('Generating %s' % output_file)\n",
    "    with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "        for input_file in tqdm(input_files):\n",
    "            inputs, labels, inputs_pw, labels_pw = restore_data(input_file)\n",
    "            num_entries_in_batch = len(inputs)\n",
    "            for i in range(num_entries_in_batch):\n",
    "                example = tf.train.Example(features=tf.train.Features(\n",
    "                    feature={\n",
    "                        'inputs': _float_feature(inputs[i].flatten().tolist()),\n",
    "                        'labels': _float_feature(labels[i].flatten().tolist()),\n",
    "                        'inputs_pw': _float_feature(inputs_pw[i].flatten().tolist()),\n",
    "                        'labels_pw': _float_feature(labels_pw[i].flatten().tolist())\n",
    "                    }))\n",
    "                record_writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir, output_dir, f):\n",
    "    for subset in ('val', 'test', 'train'):\n",
    "        input_dir = os.path.join(data_dir, subset)\n",
    "        input_files = [os.path.join(input_dir, filename) for filename in os.listdir(input_dir)]\n",
    "        output_file = os.path.join(output_dir, subset + '.tfrecords')\n",
    "        try:\n",
    "            os.remove(output_file)\n",
    "        except OSError:\n",
    "            pass\n",
    "        # Convert to tf.train.Example and write the to TFRecords.\n",
    "        f(input_files, output_file)\n",
    "        print('Done {}!'.format(subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/46 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating one_output/data_patch/val.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:09<00:00,  4.87it/s]\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done val!\n",
      "Generating one_output/data_patch/test.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:20<00:00,  4.91it/s]\n",
      "  0%|          | 0/529 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done test!\n",
      "Generating one_output/data_patch/train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 529/529 [02:01<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done train!\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'one_output/sequence_patch_data'\n",
    "output_dir = 'one_output/data_patch'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "f = lambda x, y: convert_to_tfrecord_patch(x, y)\n",
    "create_dataset(data_dir, output_dir, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/46 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating one_output/data/val.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [01:33<00:00,  2.11s/it]\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done val!\n",
      "Generating one_output/data/test.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [02:51<00:00,  1.73s/it]\n",
      "  0%|          | 0/529 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done test!\n",
      "Generating one_output/data/train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 529/529 [16:08<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done train!\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'one_output/sequence_data'\n",
    "output_dir = 'one_output/data'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "f = lambda x, y: convert_to_tfrecord(x, y, True)\n",
    "create_dataset(data_dir, output_dir, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple output: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'multiple_output/12/sequence_patch_data'\n",
    "output_dir = 'multiple_output/12/data_patch'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "f = lambda x, y: convert_to_tfrecord_patch(x, y)\n",
    "create_dataset(data_dir, output_dir, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/46 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating multiple_output/12/data/val.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [02:31<00:00,  3.27s/it]\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done val!\n",
      "Generating multiple_output/12/data/test.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [04:18<00:00,  3.43s/it]\n",
      "  0%|          | 0/529 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done test!\n",
      "Generating multiple_output/12/data/train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 455/529 [25:21<04:18,  3.50s/it]"
     ]
    }
   ],
   "source": [
    "data_dir = 'multiple_output/12/sequence_data'\n",
    "output_dir = 'multiple_output/12/data'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "f = lambda x, y: convert_to_tfrecord(x, y, True)\n",
    "create_dataset(data_dir, output_dir, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'multiple_output/12/sequence_patch_data'\n",
    "n_examples = {'train': 0, 'val': 0, 'test': 0}\n",
    "for subset in ('train', 'val', 'test'):\n",
    "    n = 0\n",
    "    subset_data_dir = os.path.join(data_dir, subset)\n",
    "    for filename in os.listdir(subset_data_dir):\n",
    "        data = restore_data(os.path.join(subset_data_dir, filename))\n",
    "        n += len(data[0])\n",
    "    n_examples[subset] = n\n",
    "print(n_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'one_output/sequence_patch_data'\n",
    "n_examples = {'train': 0, 'val': 0, 'test': 0}\n",
    "for subset in ('train', 'val', 'test'):\n",
    "    n = 0\n",
    "    subset_data_dir = os.path.join(data_dir, subset)\n",
    "    for filename in os.listdir(subset_data_dir):\n",
    "        data = restore_data(os.path.join(subset_data_dir, filename))\n",
    "        n += len(data[0])\n",
    "    n_examples[subset] = n\n",
    "print(n_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
