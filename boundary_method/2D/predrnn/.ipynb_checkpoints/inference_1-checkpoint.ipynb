{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from skimage.measure import compare_ssim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import predrnn_pp\n",
    "import dataset_utils\n",
    "from nets import models_factory\n",
    "from data_provider import datasets_factory\n",
    "from utils import preprocess\n",
    "from utils import metrics\n",
    "\n",
    "from inference import InferencePredRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modis_utils.misc import cache_data, restore_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../one_output/data_patch'\n",
    "model_name = 'predrnn_pp'\n",
    "save_dir = 'results/predrnn_pp'\n",
    "input_length = 14\n",
    "output_length = 1\n",
    "img_width = 32\n",
    "img_channel = 1\n",
    "stride = 1\n",
    "filter_size = 5\n",
    "num_hidden = [128, 64, 64, 1]\n",
    "num_layers = len(num_hidden)\n",
    "patch_size = 4\n",
    "layer_norm = True\n",
    "lr = 0.001\n",
    "reverse_input = False\n",
    "batch_size = 8\n",
    "max_iterations = 80000\n",
    "display_interval = 1\n",
    "test_interval = 2000\n",
    "snapshot_interval = 10000\n",
    "\n",
    "save_checkpoints_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"data_dir\" : data_dir,\n",
    "    \"model_name\" :  model_name,\n",
    "    \"save_dir\" : save_dir,\n",
    "    \"input_length\" : input_length,\n",
    "    \"output_length\" : output_length,\n",
    "    \"seq_length\" : input_length + output_length,\n",
    "    \"img_width\" : img_width,\n",
    "    \"img_channel\" : img_channel,\n",
    "    \"stride\" : stride,\n",
    "    \"filter_size\" : filter_size,\n",
    "    \"num_hidden\" : num_hidden,\n",
    "    \"num_layers\" : num_layers,\n",
    "    \"patch_size\" : patch_size,\n",
    "    \"layer_norm\" : layer_norm,\n",
    "    \"lr\" : lr,\n",
    "    \"reverse_input\" : reverse_input,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"max_iterations\" : max_iterations,\n",
    "    \"display_interval\" : display_interval,\n",
    "    \"test_interval\" : test_interval,\n",
    "    \"snapshot_interval\" : snapshot_interval\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2786, 14, 32, 32, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_np = restore_data(os.path.join('data', '{}.dat'.format('test')))[0]\n",
    "inputs_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import functools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import predictor\n",
    "\n",
    "import predrnn_pp\n",
    "import dataset_utils\n",
    "from utils import metrics\n",
    "from utils import preprocess\n",
    "from nets import models_factory\n",
    "from data_provider import datasets_factory\n",
    "\n",
    "sys.path.append('../../../')\n",
    "from modis_utils.misc import cache_data, restore_data\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    if isinstance(features, dict):\n",
    "        features = features['feature']\n",
    "\n",
    "    predictions = predrnn_pp.rnn(features, params[\"num_layers\"], params[\"num_hidden\"], params[\"filter_size\"],\n",
    "                                 params[\"stride\"], params[\"seq_length\"], params[\"input_length\"],\n",
    "                                 params[\"layer_norm\"])\n",
    "    predictions = predictions[:, params[\"input_length\"]-1:]\n",
    "    print(\"predictions.shape =\", predictions.shape)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    else:\n",
    "        loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions)\n",
    "        tensors_to_log = {'loss': loss}\n",
    "        logging_hook = tf.train.LoggingTensorHook(\n",
    "            tensors=tensors_to_log, every_n_iter=100)\n",
    "        train_hooks = [logging_hook]\n",
    "\n",
    "        metrics = {\n",
    "            'mse': tf.metrics.mean_squared_error(labels=labels, predictions=predictions)\n",
    "        }\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "        elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate=params[\"lr\"])\\\n",
    "                .minimize(loss, global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "\n",
    "def input_fn(data_dir, subset, batch_size,\n",
    "             use_distortion_for_training=True):\n",
    "    use_distortion = subset == 'train' and use_distortion_for_training\n",
    "    dataset = dataset_utils.ConvLSTMDataSet(data_dir, subset, use_distortion)\n",
    "    return dataset.make_batch(batch_size)\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def convert_to_tfrecord(inputs):\n",
    "    r = np.random.randint(1000000)\n",
    "    path = '.{}'.format(r)\n",
    "    with tf.python_io.TFRecordWriter(path) as record_writer:\n",
    "        num_entries_in_batch = len(inputs)\n",
    "        for i in range(num_entries_in_batch):\n",
    "            example = tf.train.Example(features=tf.train.Features(\n",
    "                feature={\n",
    "                    'inputs': _float_feature(inputs[i].flatten().tolist()),\n",
    "                }))\n",
    "            record_writer.write(example.SerializeToString())\n",
    "    return path\n",
    "\n",
    "\n",
    "def parser(serialized_example, single_example_shape):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'inputs': tf.FixedLenFeature(\n",
    "                [single_example_shape[0] * single_example_shape[1] * single_example_shape[2]],\n",
    "                tf.float32),\n",
    "        })\n",
    "    inputs = tf.reshape(features['inputs'], single_example_shape)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class InferencePredRNN:\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "        self.test_inpf = functools.partial(input_fn, params['data_dir'], 'test', params['batch_size'])\n",
    "        self.val_inpf = functools.partial(input_fn, params['data_dir'], 'val', params['batch_size'])\n",
    "        self.train_inpf = functools.partial(input_fn, params['data_dir'], 'train', params['batch_size'])\n",
    "        self.input_fn = {\n",
    "            'train': self.train_inpf,\n",
    "            'val': self.val_inpf,\n",
    "            'test': self.test_inpf\n",
    "        }\n",
    "\n",
    "        cfg = tf.estimator.RunConfig()\n",
    "        self.estimator = tf.estimator.Estimator(model_fn, params['save_dir'], cfg, params)\n",
    "\n",
    "        def serving_input_receiver_fn():\n",
    "            inputs = tf.placeholder(dtype=tf.float32,\n",
    "                shape=[params['batch_size'], params['input_length'], params['img_width'],\n",
    "                    params['img_width'], params['img_channel']], name='inputs')\n",
    "            receiver_tensors = {'feature': inputs}\n",
    "            features = inputs\n",
    "            return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
    "\n",
    "        export_dir = 'saved_model'\n",
    "        self.estimator.export_saved_model(export_dir, serving_input_receiver_fn)\n",
    "\n",
    "        subdirs = [x for x in Path(export_dir).iterdir()\n",
    "            if x.is_dir() and 'temp' not in str(x)]\n",
    "        latest = str(sorted(subdirs)[-1])\n",
    "        self.predict_fn = predictor.from_saved_model(latest)\n",
    "\n",
    "\n",
    "    def evaluate(self, subset='test'):\n",
    "        return self.estimator.evaluate(self.input_fn[subset],\n",
    "                   steps=dataset_utils.ConvLSTMDataSet.num_examples_per_epoch(subset) // self.params['batch_size'])\n",
    "\n",
    "\n",
    "    def get_inference_from_tfrecord(self, subset='test'):\n",
    "        results = self.estimator.predict(self.input_fn[subset])\n",
    "        inferences = []\n",
    "        i = 0\n",
    "        for result in tqdm(results):\n",
    "            inferences.append(result)\n",
    "            i += 1\n",
    "            if i == dataset_utils.ConvLSTMDataSet.num_examples_per_epoch(subset):\n",
    "                break\n",
    "        return np.vstack(inferences).squeeze()\n",
    "\n",
    "\n",
    "    def get_inference_from_np_array(self, inputs_np):\n",
    "        batch_size = self.params['batch_size']\n",
    "        n = len(inputs_np)\n",
    "        r = n % batch_size\n",
    "        m = n // batch_size\n",
    "        inputs_np = np.expand_dims(inputs_np, axis=-1)\n",
    "        if r > 0:\n",
    "            inputs_np = np.vstack([inputs_np, inputs_np[:batch_size - r]]) # Padding to have shape as multiple of batch_size\n",
    "            m += 1\n",
    "        results = []\n",
    "        for i in range(m):\n",
    "            result = self.predict_fn({'feature': inputs_np[i*batch_size : (i+1)*batch_size]})['output']\n",
    "            results.append(result)\n",
    "        results = np.vstack(results).squeeze()\n",
    "        if r > 0:\n",
    "            return results[:-r]\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'results/predrnn_pp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff8c4749630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "predictions.shape = (8, 1, 32, 32, 1)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from results/predrnn_pp/model.ckpt-21300\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_model/temp-b'1559120934'/saved_model.pb\n",
      "INFO:tensorflow:Restoring parameters from saved_model/1559120934/variables/variables\n"
     ]
    }
   ],
   "source": [
    "inference_predrnn = InferencePredRNN(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 27/46 [00:58<00:31,  1.65s/it]"
     ]
    }
   ],
   "source": [
    "evaluation_tfrecord = {}\n",
    "inferences_tfrecord = {}\n",
    "inferences_np = {}\n",
    "np_input_dir = '../one_output/sequence_patch_data'\n",
    "\n",
    "for subset in ('val',):\n",
    "    #evaluation_tfrecord[subset] = inference_predrnn.evaluate(subset)\n",
    "    #inferences_tfrecord[subset] = inference_predrnn.get_inference_from_tfrecord(subset)\n",
    "    \n",
    "    np_input_dir_subset = os.path.join(np_input_dir, subset)\n",
    "    n = len(os.listdir(np_input_dir_subset))\n",
    "    inferences_np[subset] = []\n",
    "    for i in tqdm(range(n)):\n",
    "        inputs_np = restore_data(os.path.join(np_input_dir_subset, '{}.dat'.format(i)))[0]\n",
    "        inferences_np[subset].append(inference_predrnn.get_inference_from_np_array(inputs_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
