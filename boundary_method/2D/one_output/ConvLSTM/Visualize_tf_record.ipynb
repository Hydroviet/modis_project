{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data_patch/val.tfrecords',\n",
       " '../data_patch/test.tfrecords',\n",
       " '../data_patch/train.tfrecords']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_records_filenames = [os.path.join('../data_patch', fn) for fn in os.listdir('../data_patch')]\n",
    "tf_records_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_patch/val.tfrecords 1380\n",
      "../data_patch/test.tfrecords 4166\n",
      "../data_patch/train.tfrecords 20262\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for fn in tf_records_filenames:\n",
    "    for record in tf.python_io.tf_record_iterator(fn):\n",
    "        c += 1\n",
    "    print(fn, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import ConvLSTMDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConvLSTMDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_steps = 14\n",
    "out_steps = 1\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "DEPTH = 1\n",
    "\n",
    "\n",
    "class ConvLSTMDataSet_1(object):\n",
    "\n",
    "  def __init__(self, data_dir='../data', subset='train', use_distortion=True):\n",
    "    self.data_dir = data_dir\n",
    "    self.subset = subset\n",
    "    self.use_distortion = use_distortion\n",
    "\n",
    "  def get_filenames(self):\n",
    "    if self.subset in ['train', 'val', 'test']:\n",
    "      return [os.path.join(self.data_dir, self.subset + '.tfrecords')]\n",
    "    else:\n",
    "      raise ValueError('Invalid data subset \"%s\"' % self.subset)\n",
    "\n",
    "  def parser(self, serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'inputs': tf.FixedLenFeature([in_steps * DEPTH * HEIGHT * WIDTH], tf.float32),\n",
    "            'labels': tf.FixedLenFeature([out_steps * DEPTH * HEIGHT * WIDTH], tf.float32),\n",
    "        })\n",
    "\n",
    "    # Reshape from [in_steps * depth * height * width] to [in_steps, height, width, depth].\n",
    "    inputs = tf.reshape(features['inputs'], [in_steps, HEIGHT, WIDTH, DEPTH])\n",
    "    labels = tf.reshape(features['labels'], [out_steps, HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "\n",
    "  def make_batch(self, batch_size, epochs=2):\n",
    "    \"\"\"Read the images and labels from 'filenames'.\"\"\"\n",
    "    filenames = self.get_filenames()\n",
    "    # Repeat infinitely.\n",
    "    dataset = tf.data.TFRecordDataset(filenames).repeat(1)\n",
    "\n",
    "    # Parse records.\n",
    "    dataset = dataset.map(\n",
    "        self.parser, num_parallel_calls=batch_size)\n",
    "\n",
    "    # Potentially shuffle records.\n",
    "    if self.subset == 'train':\n",
    "      min_queue_examples = int(\n",
    "          ConvLSTMDataSet.num_examples_per_epoch(self.subset) * 0.4)\n",
    "      # Ensure that the capacity is sufficiently large to provide good random\n",
    "      # shuffling.\n",
    "      dataset = dataset.shuffle(buffer_size=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    inputs_batch, labels_batch = iterator.get_next()\n",
    "\n",
    "    return inputs_batch, labels_batch\n",
    "\n",
    "  @staticmethod\n",
    "  def num_examples_per_epoch(subset='train'):\n",
    "    if subset == 'train':\n",
    "      return 20096\n",
    "    elif subset == 'val':\n",
    "      return 1380\n",
    "    elif subset == 'test':\n",
    "      return 4146\n",
    "    else:\n",
    "      raise ValueError('Invalid data subset \"%s\"' % subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConvLSTMDataSet_1(subset='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_batch, labels_batch = dataset.make_batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(14, 32, 32, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_dir, subset, batch_size,\n",
    "             use_distortion_for_training=True):\n",
    "    use_distortion = subset == 'train' and use_distortion_for_training\n",
    "    dataset = ConvLSTMDataSet(data_dir, subset, use_distortion)\n",
    "    return dataset.make_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data_patch'\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inpf = functools.partial(input_fn, data_dir, 'train', batch_size)\n",
    "eval_inpf = functools.partial(input_fn, data_dir, 'val', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = train_inpf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in range(21000):\n",
    "        inputs1, labels1 = sess.run([inputs, labels])\n",
    "        a.add(inputs1.mean())\n",
    "        #plt.figure()\n",
    "        #plt.imshow(labels1.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14903"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'inputs': tf.FixedLenFeature([in_steps * DEPTH * HEIGHT * WIDTH], tf.float32),\n",
    "            'labels': tf.FixedLenFeature([out_steps * DEPTH * HEIGHT * WIDTH], tf.float32),\n",
    "        })\n",
    "\n",
    "    # Reshape from [in_steps * depth * height * width] to [in_steps, height, width, depth].\n",
    "    inputs = tf.reshape(features['inputs'], [in_steps, HEIGHT, WIDTH, DEPTH])\n",
    "    labels = tf.reshape(features['labels'], [out_steps, HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2500624947921007"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.1 + 0.2001)/1.2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
