{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from skimage.measure import compare_ssim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from inference_whole_img_utils import InferenceConvLSTMWholeImg\n",
    "from gen_data_inference_utils import gen_boundary_patch, select_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modis_utils.misc import cache_data, restore_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('inferences'):\n",
    "    os.makedirs('inferences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data_patch'\n",
    "model_name = 'predrnn_pp'\n",
    "save_dir = 'result/model'\n",
    "input_length = 14\n",
    "output_length = 1\n",
    "img_width = 32\n",
    "img_channel = 1\n",
    "stride = 1\n",
    "filter_size = 3\n",
    "num_hidden = [128, 64, 64, 1]\n",
    "num_layers = len(num_hidden)\n",
    "patch_size = 4\n",
    "layer_norm = True\n",
    "lr = 0.001\n",
    "reverse_input = False\n",
    "batch_size = 8\n",
    "max_iterations = 80000\n",
    "display_interval = 1\n",
    "test_interval = 2000\n",
    "snapshot_interval = 10000\n",
    "\n",
    "save_checkpoints_steps = 100\n",
    "whole_img_width = 513\n",
    "batch_norm_decay = 0.997\n",
    "batch_norm_epsilon = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"data_dir\" : data_dir,\n",
    "    \"model_name\" :  model_name,\n",
    "    \"save_dir\" : save_dir,\n",
    "    \"input_length\" : input_length,\n",
    "    \"output_length\" : output_length,\n",
    "    \"seq_length\" : input_length + output_length,\n",
    "    \"img_width\" : img_width,\n",
    "    \"img_channel\" : img_channel,\n",
    "    \"stride\" : stride,\n",
    "    \"filter_size\" : filter_size,\n",
    "    \"num_hidden\" : num_hidden,\n",
    "    \"num_layers\" : num_layers,\n",
    "    \"patch_size\" : patch_size,\n",
    "    \"layer_norm\" : layer_norm,\n",
    "    \"lr\" : lr,\n",
    "    \"reverse_input\" : reverse_input,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"max_iterations\" : max_iterations,\n",
    "    \"display_interval\" : display_interval,\n",
    "    \"test_interval\" : test_interval,\n",
    "    \"snapshot_interval\" : snapshot_interval,\n",
    "    \"whole_img_width\" : whole_img_width,\n",
    "    \"batch_norm_decay\" : batch_norm_decay,\n",
    "    \"batch_norm_epsilon\" : batch_norm_epsilon\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 513, 513)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_np_whole_img = restore_data('../../multiscale_predrnn/data/sequence_data/test/0.dat')[0]\n",
    "inputs_np_whole_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'result/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f163514d668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "predictions.shape = (8, 1, 32, 32, 1)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from result/model/model.ckpt-20604\n",
      "WARNING:tensorflow:From /home/anhkhoa/anaconda3/envs/pytf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_model/temp-b'1559139460'/saved_model.pb\n",
      "INFO:tensorflow:Restoring parameters from saved_model/1559139460/variables/variables\n"
     ]
    }
   ],
   "source": [
    "inference_convlstm_whole_img = InferenceConvLSTMWholeImg(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [05:49<00:00, 26.50s/it]\n",
      "100%|██████████| 46/46 [20:13<00:00, 26.56s/it]\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot serialize a bytes object larger than 4 GiB",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-994af581986f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mres1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minferences_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcache_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minferences_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inferences/convlstm_whole_img.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Tan_working/modis_utils/misc.py\u001b[0m in \u001b[0;36mcache_data\u001b[0;34m(data, path)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot serialize a bytes object larger than 4 GiB"
     ]
    }
   ],
   "source": [
    "inferences_np = {}\n",
    "np_input_dir = '../../multiscale_predrnn/data/sequence_data'\n",
    "steps_ahead = 80\n",
    "\n",
    "for subset in ('test', 'val'):\n",
    "    np_input_dir_subset = os.path.join(np_input_dir, subset)\n",
    "    n = len(os.listdir(np_input_dir_subset)) if subset == 'val' else 92 - steps_ahead + 1\n",
    "    res1 = []\n",
    "    for i in tqdm(range(n)):\n",
    "        inputs_np = restore_data(os.path.join(np_input_dir_subset, '{}.dat'.format(i)))[0]\n",
    "        inputs_np = inputs_np[-timesteps:]\n",
    "        res = inference_convlstm_whole_img.get_inference_from_np_array(inputs_np, steps_ahead)\n",
    "        res1.append(res)\n",
    "    inferences_np[subset] = np.asarray(res1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_data(inferences_np['test'], 'inferences/convlstm_whole_img_test.dat')\n",
    "cache_data(inferences_np['val'], 'inferences/convlstm_whole_img_val.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
