{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import pickle\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modis_utils.misc import cache_data, restore_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = restore_data(os.path.join('cache', 'boundary_vectors_ALL_1.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 1657, 2)\n",
      "(92, 1657, 2)\n"
     ]
    }
   ],
   "source": [
    "for x in data:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boundary_vectors = data[0]\n",
    "test_boundary_vectors = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((598, 1657, 2), (92, 1657, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boundary_vectors.shape, test_boundary_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = train_boundary_vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_years = len(train_boundary_vectors)//46\n",
    "n_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 1657, 2)\n"
     ]
    }
   ],
   "source": [
    "data_train = train_boundary_vectors[:0].copy()\n",
    "data_test = test_boundary_vectors\n",
    "for i in range(n_years):\n",
    "    year = 2003 + i\n",
    "    if year != 2011 and year != 2013:\n",
    "        data_train = np.vstack([data_train, train_boundary_vectors[i*46 : (i + 1)*46]])\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 3314)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_1 = data_train.reshape(data_train.shape[0], -1)\n",
    "data_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_1 = data_test.reshape(data_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data_train_1.shape[0]):\n",
    "    var = np.var(data_train_1[:, i])\n",
    "    variants.append((var, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0),\n",
       " (15.94448046368479, 1),\n",
       " (0.0, 2),\n",
       " (17.18633707759846, 3),\n",
       " (0.0, 4),\n",
       " (17.31231936133981, 5),\n",
       " (0.0, 6),\n",
       " (17.368436469871423, 7),\n",
       " (0.0, 8),\n",
       " (16.960583667921696, 9),\n",
       " (0.0, 10),\n",
       " (17.209298692371384, 11),\n",
       " (0.0, 12),\n",
       " (17.97433564030058, 13),\n",
       " (0.31430345732631354, 14),\n",
       " (18.736474558265243, 15),\n",
       " (0.18897342561202335, 16),\n",
       " (19.518255245356123, 17),\n",
       " (0.21694214876033055, 18),\n",
       " (19.334702932400134, 19),\n",
       " (0.4399889078098393, 20),\n",
       " (20.015798559577558, 21),\n",
       " (0.45965411114062094, 22),\n",
       " (21.7000734271743, 23),\n",
       " (0.5962755237544721, 24),\n",
       " (21.93770016716399, 25),\n",
       " (0.6498812666968706, 26),\n",
       " (24.314912746645003, 27),\n",
       " (0.6691285600462435, 28),\n",
       " (24.807780937055725, 29),\n",
       " (0.6778304613413738, 30),\n",
       " (22.067006202252806, 31),\n",
       " (0.64992422940524, 32),\n",
       " (21.839401490415412, 33),\n",
       " (0.7213399678170255, 34),\n",
       " (19.034292052680094, 35),\n",
       " (0.7587097126966522, 36),\n",
       " (18.94653876798575, 37),\n",
       " (0.725023043634489, 38),\n",
       " (16.58582777421925, 39),\n",
       " (0.7830773797434736, 40),\n",
       " (16.787748597853426, 41),\n",
       " (1.55243793841491, 42),\n",
       " (15.450487431454953, 43),\n",
       " (1.6583019575372209, 44),\n",
       " (15.56269040291209, 45),\n",
       " (0.8722992079238857, 46),\n",
       " (16.067431923635738, 47),\n",
       " (0.9082199378212439, 48),\n",
       " (14.361058601134214, 49),\n",
       " (0.8024535612179537, 50),\n",
       " (12.462329516161788, 51),\n",
       " (1.0756143667296785, 52),\n",
       " (14.732838350856914, 53),\n",
       " (0.8806144448436937, 54),\n",
       " (13.799219640987982, 55),\n",
       " (0.9603337030730055, 56),\n",
       " (13.402978487400208, 57),\n",
       " (0.8567584245965413, 58),\n",
       " (13.584933368745022, 59),\n",
       " (1.224124732459498, 60),\n",
       " (13.599982033776499, 61),\n",
       " (1.1088948429127155, 62),\n",
       " (13.097533159399463, 63),\n",
       " (3.008795638113391, 64),\n",
       " (17.547782343107993, 65),\n",
       " (2.2174733240638034, 66),\n",
       " (18.664285491102813, 67),\n",
       " (2.8758026215063497, 68),\n",
       " (18.802324673092844, 69),\n",
       " (2.1781194831976753, 70),\n",
       " (21.51306847474574, 71),\n",
       " (1.5785006795919323, 72),\n",
       " (17.060745363933197, 73),\n",
       " (1.7234021778187445, 74),\n",
       " (16.056480338702364, 75),\n",
       " (1.954744645284257, 76),\n",
       " (16.12176412691965, 77),\n",
       " (5.908184786514395, 78),\n",
       " (19.57686028527239, 79),\n",
       " (4.60364948679092, 80),\n",
       " (12.367448327578934, 81),\n",
       " (4.414660438375853, 82),\n",
       " (18.52894514833851, 83),\n",
       " (162.37609164336266, 84),\n",
       " (1265.4231631489324, 85),\n",
       " (2.8684755268790325, 86),\n",
       " (22.580125451108437, 87),\n",
       " (2.739927197737818, 88),\n",
       " (24.77696886375354, 89),\n",
       " (3.612398256495181, 90),\n",
       " (24.45801371682108, 91),\n",
       " (3.2075840897373804, 92),\n",
       " (26.98693933665578, 93),\n",
       " (4.693750097642518, 94),\n",
       " (26.715481416675775, 95),\n",
       " (289.30011795216296, 96),\n",
       " (1936.7521754753238, 97),\n",
       " (0.24775031636176162, 98),\n",
       " (0.0, 99),\n",
       " (0.2467153056601416, 100),\n",
       " (0.0922253120654908, 101),\n",
       " (0.24715274414535449, 102),\n",
       " (0.1332781327625803, 103),\n",
       " (0.24548500992047997, 104),\n",
       " (0.0, 105),\n",
       " (0.14749878923276408, 106),\n",
       " (0.052273898982955536, 107),\n",
       " (0.09220578356168666, 108),\n",
       " (0.03796341139527254, 109),\n",
       " (0.7620959552562921, 110),\n",
       " (0.5556445187395522, 111),\n",
       " (0.8700690527894516, 112),\n",
       " (0.6746746551266226, 113),\n",
       " (0.37612288896873874, 114),\n",
       " (0.16599228233529661, 115),\n",
       " (0.2497500351513068, 116),\n",
       " (0.24343451702104385, 117),\n",
       " (0.24405942914277687, 118),\n",
       " (0.18091205924166912, 119),\n",
       " (0.15976268962177195, 120),\n",
       " (0.062678685809808, 121),\n",
       " (1.3757323188926556, 122),\n",
       " (0.6637386929962974, 123),\n",
       " (0.6182138449280571, 124),\n",
       " (0.6092112046743426, 125),\n",
       " (0.37183833523410775, 126),\n",
       " (0.24912121732881312, 127),\n",
       " (0.24810964083175804, 128),\n",
       " (0.20156540486494084, 129),\n",
       " (0.24990235748097925, 130),\n",
       " (0.2373103782280617, 131),\n",
       " (0.2085644206283491, 132),\n",
       " (0.11487837647830776, 133),\n",
       " (0.10751613054414226, 134),\n",
       " (0.06608445687325219, 135),\n",
       " (0.07108375384711524, 136),\n",
       " (0.03246809042478401, 137),\n",
       " (1.3159126060397757, 138),\n",
       " (0.7696573919292599, 139),\n",
       " (0.8900662406849037, 140),\n",
       " (0.7403177678139012, 141),\n",
       " (0.8991118436469869, 142),\n",
       " (0.6229163086440971, 143),\n",
       " (0.3723890390413848, 144),\n",
       " (0.5412520114358919, 145),\n",
       " (0.3169437110406349, 146),\n",
       " (0.4009943914137075, 147),\n",
       " (0.21906294427346154, 148),\n",
       " (0.49216906997453486, 149),\n",
       " (0.29450546016966367, 150),\n",
       " (0.7846240372447626, 151),\n",
       " (0.11195691230920653, 152),\n",
       " (0.460892218281804, 153),\n",
       " (0.1397655017263197, 154),\n",
       " (0.517052289521786, 155),\n",
       " (0.3169241825368308, 156),\n",
       " (2.8524738708619095, 157),\n",
       " (0.3528410067334281, 158),\n",
       " (2.306613132528239, 159),\n",
       " (1.4457185708259772, 160),\n",
       " (2.859133090659126, 161),\n",
       " (0.3994477339124185, 162),\n",
       " (2.6894030526957144, 163),\n",
       " (1.0085769188707838, 164),\n",
       " (3.671577434423284, 165),\n",
       " (1.6000249964848696, 166),\n",
       " (14.086226155696856, 167),\n",
       " (2.7234021778187443, 168),\n",
       " (5.744098486150384, 169),\n",
       " (2.2279562249058724, 170),\n",
       " (18.613601212329517, 171),\n",
       " (2.375997906544392, 172),\n",
       " (20.65701698198691, 173),\n",
       " (2.8628161664765894, 174),\n",
       " (19.516915589995158, 175),\n",
       " (2.0435446577824994, 176),\n",
       " (19.66123904450937, 177),\n",
       " (2.850067959193239, 178),\n",
       " (17.707978565514228, 179),\n",
       " (2.9068099798465843, 180),\n",
       " (21.8012623224859, 181),\n",
       " (2.0976425190207624, 182),\n",
       " (20.948725960411817, 183),\n",
       " (3.068427877329751, 184),\n",
       " (18.568470840038113, 185),\n",
       " (3.284444375009764, 186),\n",
       " (20.276617350685058, 187),\n",
       " (2.3223335780905807, 188),\n",
       " (20.06002671499321, 189),\n",
       " (2.819857363808214, 190),\n",
       " (20.476015091627744, 191),\n",
       " (2.749429767688919, 192),\n",
       " (20.610355574997268, 193),\n",
       " (3.173901326375979, 194),\n",
       " (19.116639847521448, 195),\n",
       " (2.5392093299379774, 196),\n",
       " (16.927764064428434, 197),\n",
       " (2.9609117467856088, 198),\n",
       " (18.848536924494997, 199),\n",
       " (2.983267977940603, 200),\n",
       " (15.166074302051273, 201),\n",
       " (2.3544384383446078, 202),\n",
       " (10.444953053476853, 203),\n",
       " (2.4891187176803267, 204),\n",
       " (14.361000015622803, 205),\n",
       " (3.2934157696573916, 206),\n",
       " (12.603012857566904, 207),\n",
       " (10.863753534659192, 208),\n",
       " (6.891999562561516, 209),\n",
       " (17.538268056054616, 210),\n",
       " (5.509990782546204, 211),\n",
       " (7.2297528472558525, 212),\n",
       " (29.324735584058498, 213),\n",
       " (6.804422034401411, 214),\n",
       " (26.8266689059351, 215),\n",
       " (6.02477776562671, 216),\n",
       " (24.428818603633857, 217),\n",
       " (132.87409973597465, 218),\n",
       " (592.4748121357934, 219),\n",
       " (0.10751613054414226, 220),\n",
       " (0.0, 221),\n",
       " (0.23449827368026369, 222),\n",
       " (0.0, 223),\n",
       " (0.2319400396819197, 224),\n",
       " (0.0, 225),\n",
       " (0.18897342561202335, 226),\n",
       " (0.5445054601696637, 227),\n",
       " (0.293946944960865, 228),\n",
       " (2.0740052180162163, 229),\n",
       " (0.17453795559999377, 230),\n",
       " (0.0, 231),\n",
       " (0.31151869268384136, 232),\n",
       " (0.2388609414301114, 233),\n",
       " (0.8718930150447596, 234),\n",
       " (0.3750097642519021, 235),\n",
       " (0.7834562327172742, 236),\n",
       " (1.6721593838366482, 237),\n",
       " (0.7394272680404319, 238),\n",
       " (3.4145354559515066, 239),\n",
       " (0.5369127778906092, 240),\n",
       " (7.616038369604275, 241),\n",
       " (26.055086003530757, 242),\n",
       " (9.810499304785262, 243),\n",
       " (38.96509865800122, 244),\n",
       " (145.05364870565077, 245),\n",
       " (46.84955240669282, 246),\n",
       " (241.4938875783093, 247),\n",
       " (50.03688543798529, 248),\n",
       " (236.42406927150867, 249),\n",
       " (10.658141823806028, 250),\n",
       " (14.897170710368854, 251),\n",
       " (8.926873564654972, 252),\n",
       " (11.12548235404396, 253),\n",
       " (5.793173616210219, 254),\n",
       " (9.217160868002933, 255),\n",
       " (8.203237044790576, 256),\n",
       " (8.44690590385727, 257),\n",
       " (6.159258854223626, 258),\n",
       " (6.730651158430846, 259),\n",
       " (4.733869455857769, 260),\n",
       " (6.583292974425472, 261),\n",
       " (7.220472902248122, 262),\n",
       " (6.665406427221171, 263),\n",
       " (5.016439094502336, 264),\n",
       " (6.862601352934743, 265),\n",
       " (4.839694417972472, 266),\n",
       " (6.890831758034028, 267),\n",
       " (3.893268915308785, 268),\n",
       " (6.0368854379852825, 269),\n",
       " (3.610351669296505, 270),\n",
       " (4.88252042681498, 271),\n",
       " (3.2090370104204093, 272),\n",
       " (4.134137386929963, 273),\n",
       " (4.501054539205425, 274),\n",
       " (3.5324876189285885, 275),\n",
       " (2.363624646534081, 276),\n",
       " (4.249437579090441, 277),\n",
       " (2.7797184770891588, 278),\n",
       " (4.444003968191972, 279),\n",
       " (1.542486212876314, 280),\n",
       " (4.432161883485135, 281),\n",
       " (2.553347966692184, 282),\n",
       " (7.135449702385601, 283),\n",
       " (1.2576551734912274, 284),\n",
       " (6.371264197222267, 285),\n",
       " (4.738181349497726, 286),\n",
       " (23.425147244918683, 287),\n",
       " (4.13553172210158, 288),\n",
       " (23.044403911949885, 289),\n",
       " (4.342096423940383, 290),\n",
       " (24.183321876611103, 291),\n",
       " (0.0, 292),\n",
       " (0.0, 293),\n",
       " (0.04874314549516476, 294),\n",
       " (0.18805558593322813, 295),\n",
       " (0.06608445687325219, 296),\n",
       " (0.2788240716149291, 297),\n",
       " (0.16444953053476852, 298),\n",
       " (0.15121311065631396, 299),\n",
       " (0.6649846115390022, 300),\n",
       " (1.2639511631176867, 301),\n",
       " (0.6359418206814669, 302),\n",
       " (3.5318002155946826, 303),\n",
       " (0.6514747926072896, 304),\n",
       " (4.4749800809261195, 305),\n",
       " (43.237622834288935, 306),\n",
       " (283.94888218844227, 307),\n",
       " (84.60404396256776, 308),\n",
       " (544.3824774641066, 309),\n",
       " (3.052324673092846, 310),\n",
       " (5.20659594744489, 311),\n",
       " (1.1317314752612915, 312),\n",
       " (5.392022996766078, 313),\n",
       " (3.4539713165336123, 314),\n",
       " (4.747961224202847, 315),\n",
       " (1.139292911934259, 316),\n",
       " (5.733885078660812, 317),\n",
       " (1.1054109578340547, 318),\n",
       " (5.0332804761830365, 319),\n",
       " (1.093939914699495, 320),\n",
       " (5.225280819884704, 321),\n",
       " (1.3320001874736365, 322),\n",
       " (4.902248121357933, 323),\n",
       " (0.7909825180833945, 324),\n",
       " (5.209255729663016, 325),\n",
       " (1.3967606117889668, 326),\n",
       " (4.794981955662486, 327),\n",
       " (1.9328883438266495, 328),\n",
       " (5.119592557296629, 329),\n",
       " (1.3755604680591789, 330),\n",
       " (4.664469059038573, 331),\n",
       " (1.5037611898326795, 332),\n",
       " (5.120451811464013, 333),\n",
       " (1.6440813010670376, 334),\n",
       " (4.200022653064414, 335),\n",
       " (0.6401326375978379, 336),\n",
       " (3.3832586042587756, 337),\n",
       " (4.703073005358623, 338),\n",
       " (11.317752191098126, 339),\n",
       " (3.584058491774595, 340),\n",
       " (16.229127935134123, 341),\n",
       " (4.600513209079973, 342),\n",
       " (18.480655064131604, 343),\n",
       " (201.51010404786834, 344),\n",
       " (1124.7569130903464, 345),\n",
       " (76.69007483322662, 346),\n",
       " (449.51319736287087, 347),\n",
       " (0.2737427549250888, 348),\n",
       " (1.493165023668547, 349),\n",
       " (0.13038791419956572, 350),\n",
       " (0.5012107672358577, 351),\n",
       " (0.20012810698495523, 352),\n",
       " (0.4766087581433861, 353),\n",
       " (0.6944375009764251, 354),\n",
       " (0.6684099111062507, 355),\n",
       " (0.758502710556328, 356),\n",
       " (1.7178053086284746, 357),\n",
       " (0.4754526707181803, 358),\n",
       " (4.604602477776561, 359),\n",
       " (70.89890484150666, 360),\n",
       " (438.6689098408036, 361),\n",
       " (46.81078051524005, 362),\n",
       " (305.0276562670874, 363),\n",
       " (36.48938430533207, 364),\n",
       " (5.133965536096485, 365),\n",
       " (4.03493649330563, 366),\n",
       " (4.945761533534346, 367),\n",
       " (2.962415441578527, 368),\n",
       " (4.608480838632066, 369),\n",
       " (2.4504718086519084, 370),\n",
       " (4.103110500085925, 371),\n",
       " (2.45390882532144, 372),\n",
       " (3.9076379884078793, 373),\n",
       " (2.6556617038228993, 374),\n",
       " (3.2148955615616557, 375),\n",
       " (1.7054320486181633, 376),\n",
       " (3.4097861238263367, 377),\n",
       " (1.7201057663766033, 378),\n",
       " (3.055152400443687, 379),\n",
       " (1.355032104860254, 380),\n",
       " (4.2930564451873945, 381),\n",
       " (1.5365495477198519, 382),\n",
       " (2.7009795497508167, 383),\n",
       " (1.183911637425987, 384),\n",
       " (3.3530323860707085, 385),\n",
       " (32.455342217500665, 386),\n",
       " (3.115811838960146, 387),\n",
       " (281.40086940898937, 388),\n",
       " (1409.7190746613758, 389),\n",
       " (4.973285006795919, 390),\n",
       " (19.059725976034624, 391),\n",
       " (8.523961474167695, 392),\n",
       " (21.014810417285066, 393),\n",
       " (7.100970176068991, 394),\n",
       " (28.28824462185005, 395),\n",
       " (7.379774719180117, 396),\n",
       " (26.676127575809648, 397),\n",
       " (0.24436016810136071, 398),\n",
       " (0.42222578074958206, 399),\n",
       " (0.22562452155165674, 400),\n",
       " (0.09063178615507193, 401),\n",
       " (0.22562452155165674, 402),\n",
       " (1.1590909090909092, 403),\n",
       " (0.5187278351481823, 404),\n",
       " (2.904372822571826, 405),\n",
       " (0.1870049524285647, 406),\n",
       " (0.18717680326204125, 407),\n",
       " (0.3062225624521551, 408),\n",
       " (0.8622576512677904, 409),\n",
       " (38.51921214204253, 410),\n",
       " (1.977741411364027, 411),\n",
       " (93.37131106563142, 412),\n",
       " (515.978428814698, 413),\n",
       " (34.07341155150057, 414),\n",
       " (2.4675904950866285, 415),\n",
       " (1.6121834429533346, 416),\n",
       " (2.0796489556156166, 417),\n",
       " (1.5880110609445544, 418),\n",
       " (1.8492399506319426, 419),\n",
       " (1.5872455435954322, 420),\n",
       " (2.1219672233592144, 421),\n",
       " (1.5940414629192772, 422),\n",
       " (1.4948093236888562, 423),\n",
       " (1.3695613116905432, 424),\n",
       " (1.6669843303285476, 425),\n",
       " (1.3814190192004248, 426),\n",
       " (1.2147354278304614, 427),\n",
       " (1.1619342592447937, 428),\n",
       " (1.6894499211048448, 429),\n",
       " (1.1601962224062243, 430),\n",
       " (1.3699167304597795, 431),\n",
       " (0.8400381196394259, 432),\n",
       " (1.848880626161946, 433),\n",
       " (1.0192980674592633, 434),\n",
       " (1.4306464715899323, 435),\n",
       " (0.5247855770282303, 436),\n",
       " (1.8941281694761676, 437),\n",
       " (0.8648471308722213, 438),\n",
       " (1.5263205174272363, 439),\n",
       " (10.898080738646128, 440),\n",
       " (33.11576887625178, 441),\n",
       " (13.011127341467608, 442),\n",
       " (36.05275820587731, 443),\n",
       " (9.53419441016107, 444),\n",
       " (31.517536596416132, 445),\n",
       " (6.640085769188708, 446),\n",
       " (22.908969832367315, 447),\n",
       " (0.0287654861035167, 448),\n",
       " (0.2640917683450765, 449),\n",
       " (0.07446218500523363, 450),\n",
       " (0.6979526316611727, 451),\n",
       " (0.13579340405255513, 452),\n",
       " (0.4611851458388664, 453),\n",
       " (0.23640425565154904, 454),\n",
       " (0.16680466809354938, 455),\n",
       " (0.3351091252792577, 456),\n",
       " (1.0344639035135683, 457),\n",
       " (88.29516161789749, 458),\n",
       " (450.4913059101063, 459),\n",
       " (193.31005014919774, 460),\n",
       " (830.2085800434314, 461),\n",
       " (217.39671374337988, 462),\n",
       " (1170.230795669359, 463),\n",
       " (2.0304019747223045, 464),\n",
       " (1.5219773781811932, 465),\n",
       " (1.9407934821665704, 466),\n",
       " (1.4701252948804076, 467),\n",
       " (1.6327079004514986, 468),\n",
       " (1.2161102344982737, 469),\n",
       " (1.382180630848787, 470),\n",
       " (0.9650986580012184, 471),\n",
       " (1.4334741989407742, 472),\n",
       " (1.6144331265915726, 473),\n",
       " (1.354641534784171, 474),\n",
       " (1.2460747707353652, 475),\n",
       " (0.7932517302254368, 476),\n",
       " (1.7272610101704449, 477),\n",
       " (1.4821978159321345, 478),\n",
       " (1.6799981252636351, 479),\n",
       " (0.7562530269180895, 480),\n",
       " (1.6498343982877406, 481),\n",
       " (0.9679732537611899, 482),\n",
       " (1.28230795669359, 483),\n",
       " (0.46170069833929606, 484),\n",
       " (2.031479948132294, 485),\n",
       " (0.7887367401459169, 486),\n",
       " (1.826883719476948, 487),\n",
       " (0.4458904216594542, 488),\n",
       " (2.0264494055523445, 489),\n",
       " (9.057870768173228, 490),\n",
       " (20.88527004015061, 491),\n",
       " (9.090159196363011, 492),\n",
       " (18.049450077332875, 493),\n",
       " (10.09772063303598, 494),\n",
       " (23.761037510350103, 495),\n",
       " (215.2144698401787, 496),\n",
       " (919.7696612976301, 497),\n",
       " (0.24943757909044045, 498),\n",
       " (0.8588948429127152, 499),\n",
       " (0.2927869518348983, 500),\n",
       " (5.001749753940852, 501),\n",
       " (0.20359636926057273, 502),\n",
       " (0.7577996844193785, 503),\n",
       " (0.21720773641206706, 504),\n",
       " (1.5521879735662172, 505)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_1 = variants.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00],\n",
       "       [1.59444805e+01, 1.00000000e+00],\n",
       "       [0.00000000e+00, 2.00000000e+00],\n",
       "       ...,\n",
       "       [7.57799684e-01, 5.03000000e+02],\n",
       "       [2.17207736e-01, 5.04000000e+02],\n",
       "       [1.55218797e+00, 5.05000000e+02]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants_2 = np.asarray(variants_1)\n",
    "variants_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   3,   5,   7,   9,  11,  13,  15,  17,  19,  21,  23,  25,\n",
       "         27,  29,  31,  33,  35,  37,  39,  41,  43,  45,  47,  49,  51,\n",
       "         53,  55,  57,  59,  61,  63,  64,  65,  66,  67,  68,  69,  70,\n",
       "         71,  73,  75,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,\n",
       "         87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97, 157, 159,\n",
       "        161, 163, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
       "        177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n",
       "        190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n",
       "        203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
       "        216, 217, 218, 219, 229, 239, 241, 242, 243, 244, 245, 246, 247,\n",
       "        248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "        261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "        274, 275, 276, 277, 278, 279, 281, 282, 283, 285, 286, 287, 288,\n",
       "        289, 290, 291, 303, 305, 306, 307, 308, 309, 310, 311, 313, 314,\n",
       "        315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 338,\n",
       "        339, 340, 341, 342, 343, 344, 345, 346, 347, 359, 360, 361, 362,\n",
       "        363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
       "        377, 379, 381, 383, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "        394, 395, 396, 397, 405, 410, 412, 413, 414, 415, 417, 421, 440,\n",
       "        441, 442, 443, 444, 445, 446, 447, 458, 459, 460, 461, 462, 463,\n",
       "        464, 485, 489, 490, 491, 492, 493, 494, 495, 496, 497, 501]),)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(variants_2[:,0] > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_idx = np.where(variants_2[:, 0] > 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_pickle(data, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_data_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def create_empty_list(n):\n",
    "    res = []\n",
    "    for _ in range(n):\n",
    "        res.append(None)\n",
    "    return res\n",
    "\n",
    "def mse(x, y):\n",
    "    return np.mean((x - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSARIMA:\n",
    "\n",
    "    def __init__(self, data_train=None, data_test=None, list_idx=None, mode='train'):\n",
    "        self.data_train = data_train\n",
    "        self.data_test = data_test\n",
    "        self.n_data = data_train.shape[-1]\n",
    "        self.log = 'log.csv'\n",
    "        self.model_dir = 'sarima'\n",
    "        self.train_loss = None\n",
    "        self.mean_train_loss = None\n",
    "        \n",
    "        if list_idx is None:\n",
    "            self.list_idx = list(range(self.n_data))\n",
    "        else:\n",
    "            self.list_idx = list_idx\n",
    "            \n",
    "        self.list_small_variant_idx = np.setdiff1d(np.arange(self.n_data), self.list_idx)\n",
    "\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "            \n",
    "        with open(self.log, 'a') as f:\n",
    "            f.write('running_time, idx, train_loss, test_loss\\n')\n",
    "\n",
    "        self.data_train_path = 'data_train_df.dat'\n",
    "        self.data_test_path = 'data_test_df.dat'\n",
    "        if self.data_train is not None:\n",
    "            save_data_pickle(self.data_train, self.data_train_path)\n",
    "        if self.data_test is not None:\n",
    "            save_data_pickle(self.data_test, self.data_test_path)\n",
    "\n",
    "        self.mode = mode\n",
    "        if self.mode == 'inference':\n",
    "            self.load_model(self.model_dir)\n",
    "            \n",
    "\n",
    "    def load_model(self, model_dir=None):\n",
    "        if model_dir is None:\n",
    "            model_dir=self.model_dir\n",
    "        self.model_paths = []\n",
    "        for i in range(self.n_data):\n",
    "            self.model_paths.append(os.path.join(model_dir, '{}.dat'.format(i)))\n",
    "        return self.model_paths\n",
    "\n",
    "    def train(self):\n",
    "        for idx in self.list_idx:\n",
    "            self._train(self.data_train[:, idx], self.data_test[:, idx], idx)\n",
    "        for idx in self.list_small_variant_idx:\n",
    "            model_path = os.path.join(self.model_dir, '{}.dat'.format(idx))\n",
    "            mean_data = int(np.mean(self.data_train[:, idx]))\n",
    "            cache_data(mean_data, model_path)\n",
    "        self.load_model(self.model_dir)\n",
    "        return self.model_paths\n",
    "\n",
    "    def _train(self, data_train_idx, data_test_idx, idx):\n",
    "        start_time = time()\n",
    "        mod = sm.tsa.statespace.SARIMAX(data_train_idx,\n",
    "                                        order=(1, 0, 1),\n",
    "                                        seasonal_order=(1, 1, 0, 46),\n",
    "                                        enforce_stationarity=False,\n",
    "                                        enforce_invertibility=False)\n",
    "        model_fit = mod.fit()\n",
    "        train_loss = self.calc_loss_idx(model_fit, data_train_idx, 'train', 150)\n",
    "        test_loss = self.calc_loss_idx(model_fit, data_test_idx, 'test')\n",
    "\n",
    "        end_time = time()\n",
    "        running_time = end_time - start_time\n",
    "        with open(self.log, 'a') as f:\n",
    "            f.write('{:11.3f}s,{:5d},{:11.3f},{:10.3f}\\n'.format(running_time, idx, train_loss, test_loss))\n",
    "        print('{:11.3f}s,{:5d},{:11.3f},{:10.3f}'.format(running_time, idx, train_loss, test_loss))\n",
    "        \n",
    "        model_path = os.path.join(self.model_dir, '{}.dat'.format(idx))\n",
    "        save_data_pickle(model_fit, model_path)\n",
    "        return model_path\n",
    "    \n",
    "    def calc_loss_idx(self, model_fit, data_test, type='test', start=None):\n",
    "        steps = data_test.shape[0]\n",
    "        if type == 'train':\n",
    "            forecast = model_fit.get_prediction(start=start)\n",
    "            forecast = forecast.predicted_mean\n",
    "            data_test = data_test[start:]\n",
    "        else:\n",
    "            forecast = model_fit.forecast(steps)\n",
    "        loss = mse(forecast, data_test)\n",
    "        return loss\n",
    "\n",
    "    def inference(self, steps=1):\n",
    "        assert len(os.listdir(self.model_dir)) >= data_test.shape[0]\n",
    "        res = create_empty_list()\n",
    "        for i in self.list_idx:\n",
    "            model_path = self.model_paths[i]\n",
    "            model = load_data_pickle(model_path)\n",
    "            forecast = model.forecast(steps)\n",
    "            res[i] = np.expand_dims(forecast, axis=-1)\n",
    "        for i in self.list_small_variant_idx:\n",
    "            model_path = self.model_paths[i]\n",
    "            mean_data = load_data_pickle(model_path)\n",
    "            forecast = np.ones((steps, 1))*mean_data\n",
    "            res[i] = np.expand_dims(forecast, axis=-1)\n",
    "        return np.concatenate(res, axis=1)\n",
    "\n",
    "    def eval(self, groundtruth):\n",
    "        steps = groundtruth.shape[0]\n",
    "        predictions = self.inference(steps)\n",
    "        loss = (groundtruth - predictions)**2\n",
    "        return loss.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    vsarima = VSARIMA(data_train_1, data_test_1, list_idx, mode='train')\n",
    "    model_paths = vsarima.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4.606s,    1,      3.612,     5.725\n",
      "      4.851s,    3,      3.590,     7.269\n",
      "      4.762s,    5,      4.115,     5.959\n",
      "      4.889s,    7,      3.281,     7.720\n",
      "      4.603s,    9,      3.939,     6.322\n",
      "      4.887s,   11,      3.347,     7.237\n",
      "      4.668s,   13,      3.735,     8.464\n",
      "      4.881s,   15,      3.805,     5.415\n",
      "      4.415s,   17,      4.188,     6.908\n",
      "      4.702s,   19,      4.647,     6.064\n",
      "      4.516s,   21,      4.056,     6.655\n",
      "      5.142s,   23,      4.819,     6.867\n",
      "      4.604s,   25,      5.285,     8.118\n",
      "      4.955s,   27,      4.684,     9.254\n",
      "      4.925s,   29,      4.421,     9.271\n",
      "      4.932s,   31,      4.099,     8.119\n",
      "      5.082s,   33,      3.612,     7.146\n",
      "      4.598s,   35,      3.180,     5.975\n",
      "      4.974s,   37,      2.672,     5.462\n",
      "      4.011s,   39,      2.502,     4.901\n",
      "      4.210s,   41,      2.997,     5.496\n",
      "      5.467s,   42,      1.391,     1.688\n",
      "      4.260s,   43,      4.402,     5.612\n",
      "      5.286s,   44,      1.865,     1.676\n",
      "      4.494s,   45,      4.931,     7.152\n",
      "      4.547s,   47,      4.671,     5.931\n",
      "      4.622s,   49,      2.493,     3.916\n",
      "      4.361s,   51,      2.352,     3.160\n",
      "      5.229s,   52,      0.442,     0.592\n",
      "      4.642s,   53,      3.291,     4.629\n",
      "      6.306s,   55,      3.463,     4.864\n",
      "      4.499s,   57,      3.573,     5.246\n",
      "      4.486s,   59,      2.778,     3.948\n",
      "      5.192s,   60,      0.398,     0.528\n",
      "      4.645s,   61,      3.111,     4.362\n",
      "      5.603s,   62,      0.360,     0.340\n",
      "      5.134s,   63,      4.438,     4.777\n",
      "      4.864s,   64,      2.145,     2.435\n",
      "      5.272s,   65,      5.914,     6.259\n",
      "      5.352s,   66,      1.918,     1.760\n",
      "      4.919s,   67,      7.164,     8.996\n",
      "      4.540s,   68,      2.207,     2.882\n",
      "      7.075s,   69,      8.683,     7.575\n",
      "      4.795s,   70,      1.817,     2.409\n",
      "      4.801s,   71,      9.231,    10.116\n",
      "      4.951s,   72,      0.486,     0.501\n",
      "      4.749s,   73,      5.621,     5.034\n",
      "      4.953s,   74,      0.464,     0.459\n",
      "      4.474s,   75,      5.556,     5.037\n",
      "      5.257s,   76,      0.688,     0.671\n",
      "      4.552s,   77,      4.804,     4.598\n",
      "      4.715s,   78,      6.897,     5.082\n",
      "      4.879s,   79,     11.052,     9.937\n",
      "      4.731s,   80,      5.396,     4.042\n",
      "      4.947s,   81,      9.204,     7.855\n",
      "      5.008s,   82,      5.168,     4.340\n",
      "      5.317s,   83,     11.716,    12.085\n",
      "      6.080s,   84,    194.708,   230.477\n",
      "      6.802s,   85,   1441.898,  1579.204\n",
      "      5.328s,   86,      0.635,     1.258\n",
      "      5.227s,   87,      5.738,     9.932\n",
      "      4.826s,   88,      0.796,     1.180\n",
      "      4.054s,   89,      5.775,     8.584\n",
      "      4.430s,   90,      1.065,     1.019\n",
      "      4.631s,   91,      5.282,     7.144\n",
      "      4.805s,   92,      0.841,     1.259\n",
      "      4.470s,   93,      6.151,     7.529\n",
      "      4.804s,   94,      1.097,     1.456\n",
      "      5.190s,   95,      5.990,     8.526\n",
      "     11.474s,   96,    414.812,   528.896\n",
      "     14.568s,   97,   2720.391,  3488.074\n",
      "      5.164s,  122,      1.817,     1.198\n",
      "      4.775s,  138,      1.575,     1.265\n",
      "      4.737s,  157,      3.296,     3.582\n",
      "      5.156s,  159,      2.516,     2.616\n",
      "      7.338s,  160,      2.104,     0.618\n",
      "      4.769s,  161,      2.828,     2.474\n",
      "      4.649s,  163,      2.771,     2.066\n",
      "      5.102s,  164,      1.296,     0.922\n",
      "      4.491s,  165,      3.388,     2.188\n",
      "      5.249s,  166,      1.859,     1.388\n",
      "      4.317s,  167,     15.465,     9.929\n",
      "      5.172s,  168,      4.329,     2.274\n",
      "      4.026s,  169,      4.999,     3.687\n",
      "      5.083s,  170,      2.181,     1.717\n",
      "      5.327s,  171,     15.890,    11.309\n",
      "      6.266s,  172,      2.073,     1.644\n",
      "      4.904s,  173,     14.732,    10.733\n",
      "      5.761s,  174,      2.380,     2.087\n",
      "      4.979s,  175,     13.125,     9.807\n",
      "      4.809s,  176,      1.512,     1.502\n",
      "      5.519s,  177,     13.423,    11.103\n",
      "      4.954s,  178,      2.320,     1.429\n",
      "      4.879s,  179,     11.997,    10.192\n",
      "      4.935s,  180,      2.410,     1.978\n",
      "      4.892s,  181,     12.986,     9.747\n",
      "      5.470s,  182,      1.679,     1.342\n",
      "      4.889s,  183,     12.479,    10.571\n",
      "      4.721s,  184,      2.019,     1.644\n",
      "      4.873s,  185,     12.450,     9.798\n",
      "      4.812s,  186,      2.907,     1.369\n",
      "      4.673s,  187,     10.741,    10.727\n",
      "      5.303s,  188,      1.924,     1.185\n",
      "      4.901s,  189,     12.353,     9.749\n",
      "      4.787s,  190,      2.396,     1.183\n",
      "      4.835s,  191,      9.705,     9.073\n",
      "      6.257s,  192,      2.321,     1.560\n",
      "      4.593s,  193,      9.673,     9.946\n",
      "      4.716s,  194,      2.701,     2.557\n",
      "      4.936s,  195,      9.106,     8.778\n",
      "      6.006s,  196,      2.255,     1.218\n",
      "      5.168s,  197,     10.559,    10.256\n",
      "      7.275s,  198,      2.933,     1.937\n",
      "      4.860s,  199,      8.946,     9.483\n",
      "      4.241s,  200,      2.583,     1.570\n",
      "      5.005s,  201,      9.107,     8.956\n",
      "      5.654s,  202,      2.377,     2.205\n",
      "      4.722s,  203,      7.532,     6.410\n",
      "      4.387s,  204,      2.563,     1.883\n",
      "      5.005s,  205,      9.065,     8.118\n",
      "      4.480s,  206,      3.196,     2.036\n",
      "      4.823s,  207,      9.341,     7.673\n",
      "      5.131s,  208,     18.405,     8.605\n",
      "      5.032s,  209,      5.339,     4.516\n",
      "     13.581s,  210,     28.108,    26.560\n",
      "      5.007s,  211,      4.870,     4.715\n",
      "      5.387s,  212,      7.745,     4.181\n",
      "      4.654s,  213,     18.549,    12.185\n",
      "      4.963s,  214,      7.126,     4.337\n",
      "      5.647s,  215,     14.941,    13.788\n",
      "      8.629s,  216,      6.849,     4.352\n",
      "      4.961s,  217,     11.703,    14.916\n",
      "      5.644s,  218,    177.522,   261.871\n",
      "      7.701s,  219,    769.747,   827.634\n",
      "      5.041s,  229,      3.100,     2.705\n",
      "      5.372s,  237,      2.226,     2.250\n",
      "      4.995s,  239,      4.080,     5.125\n",
      "      5.473s,  241,      8.516,     9.588\n",
      "     16.101s,  242,     33.744,    41.850\n",
      "      5.839s,  243,     11.438,    11.734\n",
      "      5.599s,  244,     45.580,    63.844\n",
      "      8.212s,  245,    175.140,   177.970\n",
      "      5.874s,  246,     51.652,    64.496\n",
      "      5.794s,  247,    277.202,   372.022\n",
      "      5.905s,  248,     57.719,    66.591\n",
      "      6.100s,  249,    284.588,   328.630\n",
      "      4.803s,  250,     11.494,    12.151\n",
      "      4.737s,  251,     14.844,    17.286\n",
      "      4.426s,  252,     10.175,     9.333\n",
      "      5.050s,  253,     10.708,    13.115\n",
      "      5.499s,  254,      7.668,     7.397\n",
      "      5.914s,  255,      8.142,    12.337\n",
      "      5.419s,  256,      9.575,     6.988\n",
      "      4.913s,  257,      7.104,    10.206\n",
      "      4.842s,  258,      8.677,     7.861\n",
      "      4.685s,  259,      5.316,     8.664\n",
      "      4.837s,  260,      6.687,     5.061\n",
      "      4.910s,  261,      4.536,     6.263\n",
      "      4.477s,  262,      8.557,     7.084\n",
      "      5.089s,  263,      5.352,     6.913\n",
      "      5.433s,  264,      6.848,     5.902\n",
      "      4.877s,  265,      5.629,     7.064\n",
      "      5.847s,  266,      6.121,     4.678\n",
      "      4.945s,  267,      4.873,     6.947\n",
      "      5.136s,  268,      5.258,     4.090\n",
      "      4.771s,  269,      4.517,     6.914\n",
      "      5.010s,  270,      3.712,     4.055\n",
      "      5.496s,  271,      3.533,     4.807\n",
      "      6.011s,  272,      4.037,     4.315\n",
      "      4.896s,  273,      3.213,     3.982\n",
      "      5.448s,  274,      5.561,     5.794\n",
      "      4.903s,  275,      3.052,     3.717\n",
      "      5.185s,  276,      2.816,     2.991\n",
      "      5.193s,  277,      2.872,     3.293\n",
      "      5.308s,  278,      3.619,     3.935\n",
      "      5.054s,  279,      3.321,     3.963\n",
      "      5.830s,  280,      1.874,     1.557\n",
      "      7.494s,  281,      2.949,     3.060\n",
      "      5.775s,  282,      3.060,     3.030\n",
      "      5.315s,  283,      5.989,     6.210\n",
      "      7.695s,  284,      1.588,     1.461\n",
      "      5.483s,  285,      5.144,     6.162\n",
      "      9.909s,  286,      3.097,     1.582\n",
      "      5.625s,  287,      9.585,     5.990\n",
      "      4.990s,  288,      1.464,     1.454\n",
      "      5.531s,  289,      9.445,     7.783\n",
      "      5.058s,  290,      2.095,     1.603\n",
      "      5.566s,  291,      9.676,     7.350\n",
      "     12.107s,  301,      1.760,     1.934\n",
      "      9.253s,  303,      4.830,     5.234\n",
      "      6.113s,  305,      6.367,     5.611\n",
      "      5.435s,  306,     69.067,    52.942\n",
      "      7.352s,  307,    453.079,   442.569\n",
      "      6.340s,  308,    127.590,   123.173\n",
      "     14.726s,  309,    807.362,   803.122\n",
      "      4.977s,  310,      2.190,     2.622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4.576s,  311,      3.457,     3.117\n",
      "      5.257s,  312,      0.893,     0.735\n",
      "      4.855s,  313,      3.547,     3.935\n",
      "      5.016s,  314,      2.486,     4.657\n",
      "      5.173s,  315,      2.828,     3.010\n",
      "      5.421s,  316,      0.987,     0.704\n",
      "      4.780s,  317,      3.675,     4.105\n",
      "      5.402s,  318,      1.040,     0.770\n",
      "      4.393s,  319,      3.149,     3.146\n",
      "      6.199s,  320,      0.990,     0.891\n",
      "      4.618s,  321,      3.148,     3.919\n",
      "      5.009s,  322,      1.606,     0.892\n",
      "      4.587s,  323,      2.898,     3.166\n",
      "      4.598s,  325,      2.964,     3.952\n",
      "      5.831s,  326,      1.795,     1.060\n",
      "      5.190s,  327,      2.610,     2.853\n",
      "      8.727s,  328,      2.185,     1.444\n",
      "      4.882s,  329,      2.637,     3.876\n",
      "      8.193s,  330,      1.871,     1.761\n",
      "      4.255s,  331,      2.434,     3.377\n",
      "      5.618s,  332,      1.889,     1.015\n",
      "      4.397s,  333,      2.578,     3.698\n",
      "      9.903s,  334,      2.373,     1.644\n",
      "      4.680s,  335,      2.102,     3.017\n",
      "      4.485s,  337,      1.958,     2.517\n",
      "      7.298s,  338,      5.186,     3.183\n",
      "      6.405s,  339,      7.684,     5.133\n",
      "      9.926s,  340,      3.129,     2.136\n",
      "      4.829s,  341,     10.552,     6.804\n",
      "      7.040s,  342,      5.557,     3.472\n",
      "      4.710s,  343,     12.341,     7.797\n",
      "     18.211s,  344,    310.311,   229.189\n",
      "     22.433s,  345,   1741.115,  1273.800\n",
      "      5.881s,  346,    106.970,    70.690\n",
      "      7.347s,  347,    623.539,   441.275\n",
      "     11.066s,  349,      2.188,     2.691\n",
      "      6.021s,  357,      2.444,     3.011\n",
      "      6.522s,  359,      7.206,     7.002\n",
      "      6.549s,  360,    115.927,   113.336\n",
      "      9.245s,  361,    740.271,   785.849\n",
      "      6.291s,  362,     70.352,    62.470\n",
      "     13.539s,  363,    449.342,   405.396\n",
      "      5.993s,  364,     48.870,    28.885\n",
      "      5.230s,  365,      4.344,     4.578\n",
      "     11.223s,  366,      5.408,     3.050\n",
      "      4.504s,  367,      3.298,     4.218\n",
      "      6.544s,  368,      3.857,     2.623\n",
      "      4.251s,  369,      2.735,     3.682\n",
      "     10.619s,  370,      3.119,     3.296\n",
      "      4.975s,  371,      2.496,     2.571\n",
      "      4.735s,  372,      2.400,     2.230\n",
      "      6.060s,  373,      2.509,     3.595\n",
      "      5.875s,  374,      2.989,     2.377\n",
      "      4.668s,  375,      2.024,     3.241\n",
      "      6.821s,  376,      2.011,     1.917\n",
      "      4.829s,  377,      2.058,     3.764\n",
      "      8.226s,  378,      2.169,     2.145\n",
      "      4.791s,  379,      1.706,     3.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhkhoa/anaconda3/envs/pytf/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18.393s,  380,      1.582,     1.330\n",
      "      5.205s,  381,      2.622,     3.492\n",
      "      6.293s,  382,      1.888,     1.864\n",
      "      4.155s,  383,      1.705,     2.671\n",
      "      6.594s,  384,      1.305,     1.437\n",
      "      4.484s,  385,      2.162,     3.846\n",
      "     12.301s,  386,     44.006,    47.005\n",
      "      4.747s,  387,      2.168,     3.185\n",
      "      8.709s,  388,    380.966,   300.616\n",
      "     14.384s,  389,   1960.016,  1536.788\n",
      "      5.045s,  390,      5.747,     5.289\n",
      "      5.851s,  391,     18.033,    14.472\n",
      "      5.737s,  392,     10.863,     7.953\n",
      "      5.027s,  393,     19.871,    19.086\n",
      "      5.252s,  394,      8.590,     8.683\n",
      "      7.920s,  395,     24.350,    21.766\n",
      "      5.832s,  396,      8.785,     9.081\n",
      "      5.566s,  397,     24.072,    27.081\n",
      "     10.933s,  403,      1.611,     1.403\n",
      "      6.951s,  405,      3.877,     5.211\n",
      "      6.873s,  410,     65.537,    38.616\n",
      "      7.211s,  411,      2.751,     3.086\n",
      "      7.617s,  412,    157.373,   116.536\n",
      "     24.779s,  413,    871.447,   604.749\n",
      "      4.907s,  414,     55.400,    76.632\n",
      "      5.131s,  415,      2.187,     1.992\n",
      "      5.945s,  416,      2.351,     1.366\n",
      "      5.537s,  417,      1.511,     1.914\n",
      "      7.352s,  418,      2.065,     1.763\n",
      "      4.768s,  419,      1.405,     1.460\n",
      "      6.247s,  420,      1.999,     1.531\n",
      "      4.877s,  421,      1.507,     2.126\n",
      "      5.196s,  422,      2.147,     1.920\n",
      "      5.947s,  423,      1.146,     1.351\n",
      "      5.499s,  424,      1.571,     1.350\n",
      "      4.822s,  425,      1.260,     1.598\n",
      "     10.908s,  426,      2.181,     1.215\n",
      "      5.034s,  427,      0.761,     1.047\n",
      "      5.598s,  428,      1.279,     0.971\n",
      "      5.061s,  429,      1.288,     1.691\n",
      "     10.159s,  430,      1.719,     1.091\n",
      "      5.489s,  431,      0.884,     1.377\n",
      "      4.655s,  433,      1.247,     2.078\n",
      "      5.735s,  434,      1.310,     1.407\n",
      "      4.624s,  435,      1.004,     1.461\n",
      "      4.691s,  437,      1.252,     2.005\n",
      "      5.126s,  439,      1.190,     1.639\n",
      "      5.925s,  440,     11.854,    11.283\n",
      "      8.406s,  441,     28.606,    25.502\n",
      "      5.973s,  442,     15.622,    13.109\n",
      "      5.892s,  443,     29.471,    27.142\n",
      "      6.862s,  444,     11.672,     6.564\n",
      "      6.137s,  445,     25.108,    17.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhkhoa/anaconda3/envs/pytf/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17.292s,  446,      9.509,     4.972\n",
      "     11.697s,  447,     19.204,    11.062\n",
      "      8.656s,  457,      1.485,     1.467\n",
      "      6.219s,  458,    131.416,    96.786\n",
      "      6.429s,  459,    651.462,   401.317\n",
      "      7.027s,  460,    251.857,   216.135\n",
      "      6.717s,  461,   1073.138,   906.708\n",
      "      7.176s,  462,    277.703,   241.993\n",
      "      8.538s,  463,   1509.651,  1327.409\n",
      "      5.342s,  464,      2.727,     1.821\n",
      "      9.076s,  465,      1.484,     1.225\n",
      "      5.460s,  466,      2.270,     1.730\n",
      "      8.371s,  467,      1.250,     1.285\n",
      "      5.844s,  468,      2.197,     1.109\n",
      "     10.344s,  469,      1.090,     1.145\n"
     ]
    }
   ],
   "source": [
    "vsarima = VSARIMA(data_train_1, data_test_1, list_idx, mode='train')\n",
    "model_paths = vsarima.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = vsarima.eval(data_test_1)\n",
    "print(losses.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
