{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9-Nn0CsF1L44",
    "outputId": "39830814-9386-4ff9-ebe5-497abc9c37e7"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('gdrive')\n",
    "    gdrive_dir = 'cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_sIeTMQ1JIa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exE_fQWg1JIh"
   },
   "outputs": [],
   "source": [
    "from modis_utils.misc import cache_data, restore_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5r9tSawW1JIl"
   },
   "outputs": [],
   "source": [
    "data = restore_data(os.path.join('cache', 'boundary_vectors_ALL.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cReEtZNI1JIn"
   },
   "outputs": [],
   "source": [
    "train_boundary_vectors = data[0]\n",
    "val_boundary_vectors = data[1]\n",
    "test_boundary_vectors = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Evr_F7S31JIq",
    "outputId": "a05d7af0-96f1-4324-b4e4-bb01f1e713e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_points = train_boundary_vectors.shape[1]\n",
    "n_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kcNKTrpr1JIu",
    "outputId": "76513dc6-8445-4f9e-e3e5-0b69d32ae833"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((438, 1024, 2), (138, 1024, 2), (138, 1024, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boundary_vectors.shape, val_boundary_vectors.shape, test_boundary_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoC45MTR1JIy"
   },
   "outputs": [],
   "source": [
    "def transform(data, scaler):\n",
    "    old_shape = data.shape\n",
    "    data = data.reshape(old_shape[0], -1)\n",
    "    if scaler is not None:\n",
    "        data = scaler.transform(data.astype(np.float))\n",
    "    #return data.reshape(old_shape)\n",
    "    return data\n",
    "  \n",
    "def transform_standardize(data, mean, std):\n",
    "    old_shape = data.shape\n",
    "    data = data.reshape(old_shape[0], -1)\n",
    "    data = (data - mean)/std\n",
    "    return data.reshape(old_shape)\n",
    "    #return data\n",
    "    \n",
    "def find_mean_std(data):\n",
    "    old_shape = data.shape\n",
    "    data = data.reshape(old_shape[0], -1)\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    std[std == 0] = 1\n",
    "    #mean = mean.reshape(-1, old_shape[-1])\n",
    "    #std = std.reshape(-1, old_shape[-1])\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLqx4tD-1JI0"
   },
   "outputs": [],
   "source": [
    "scaler = None\n",
    "scale_data = False\n",
    "if scale_data:\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(train_boundary_vectors.reshape(train_boundary_vectors.shape[0], -1))\n",
    "    \n",
    "mean, std = find_mean_std(train_boundary_vectors)\n",
    "train_boundary_vectors_1 = transform_standardize(train_boundary_vectors, mean, std)\n",
    "val_boundary_vectors_1 = transform_standardize(val_boundary_vectors, mean, std)\n",
    "test_boundary_vectors_1 = transform_standardize(test_boundary_vectors, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZvotXRA1JI3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_boundary_vectors_scale_1 = transform(train_boundary_vectors, scaler, flatten=False)\\nval_boundary_vectors_scale_1 = transform(val_boundary_vectors, scaler, flatten=False)\\ntest_boundary_vectors_scale_1 = transform(test_boundary_vectors, scaler, flatten=False)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the dataset\n",
    "'''\n",
    "train_boundary_vectors_scale_1 = transform(train_boundary_vectors, scaler, flatten=False)\n",
    "val_boundary_vectors_scale_1 = transform(val_boundary_vectors, scaler, flatten=False)\n",
    "test_boundary_vectors_scale_1 = transform(test_boundary_vectors, scaler, flatten=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XLY_Cuit1JI5",
    "outputId": "2258351d-7359-4b75-81ef-8de5fe2e36a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 1024, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boundary_vectors_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-u5aVh31JI9"
   },
   "outputs": [],
   "source": [
    "def create_dataset(boundary_vectors_scale, timesteps):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    for i in range(len(boundary_vectors_scale) - timesteps):\n",
    "        data_x = boundary_vectors_scale[i:(i+timesteps)]\n",
    "        data_y = boundary_vectors_scale[i + timesteps]\n",
    "        data_X.append(data_x)\n",
    "        data_Y.append(data_y)\n",
    "    return np.asarray(data_X), np.asarray(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvuWC_3k1JI_"
   },
   "outputs": [],
   "source": [
    "timesteps = 50\n",
    "train_X, train_Y = create_dataset(train_boundary_vectors_1, timesteps)\n",
    "val_X, val_Y = create_dataset(np.concatenate(\n",
    "    [train_boundary_vectors_1[-timesteps:], val_boundary_vectors_1]),\n",
    "                              timesteps)\n",
    "test_X, test_Y = create_dataset(np.concatenate(\n",
    "    [val_boundary_vectors_1[-timesteps:], test_boundary_vectors_1]),\n",
    "                                timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "CILpLtpU1JJF",
    "outputId": "2af30de8-0b8c-4186-ab0d-4d6ff99b25f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((388, 50, 1024, 2),\n",
       " (388, 1024, 2),\n",
       " (138, 50, 1024, 2),\n",
       " (138, 1024, 2),\n",
       " (138, 50, 1024, 2),\n",
       " (138, 1024, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape, val_X.shape, val_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBL1WZ0B1JJN"
   },
   "outputs": [],
   "source": [
    "def create_graph_matrix(n_points_on_boundary):\n",
    "    def calc_arc_distance(a, b, n):\n",
    "        diff = np.abs(a-b)\n",
    "        if diff > n//2:\n",
    "            diff = n - diff\n",
    "        return diff\n",
    "    \n",
    "    n = n_points_on_boundary\n",
    "    mat = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mat[i,j] = calc_arc_distance(i, j, n)\n",
    "    return mat.astype(np.float32)\n",
    "\n",
    "def create_graph_matrix_1(n_points_on_boundary):\n",
    "    def calc_arc_distance(a, b, n):\n",
    "        diff = np.abs(a-b)\n",
    "        if diff > n//2:\n",
    "            diff = n - diff\n",
    "        return diff\n",
    "    \n",
    "    n = n_points_on_boundary\n",
    "    mat = np.zeros((2*n, 2*n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mat[i,j] = calc_arc_distance(i, j, n)\n",
    "    mat[n:2*n, n:2*n] = mat[:n, :n]\n",
    "    for i in range(n):\n",
    "        for j in range(n, 2*n):\n",
    "            mat[i,j] = mat[i, j - n]\n",
    "    mat[n:2*n, :n] = mat[:n, n:2*n]\n",
    "    return mat.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A_HxgB4J1JJQ",
    "outputId": "25202c70-6c2c-4da8-f193-7fb60fc30dd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = create_graph_matrix(n_points)\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQvNkxc62bOP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0rpImRf1JJc"
   },
   "outputs": [],
   "source": [
    "#from grnn.model_keras import GRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vm584opiCXWO"
   },
   "outputs": [],
   "source": [
    "A = np.divide(mat, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import GRU, GRUCell, Layer\n",
    "\n",
    "def bmm(H, A, n_nodes):\n",
    "    current_shape = K.shape(H)\n",
    "    H = K.reshape(H, [-1, n_nodes])\n",
    "    M = K.dot(H, A)\n",
    "    return K.reshape(M, current_shape)\n",
    "\n",
    "class GRNN(Layer):\n",
    "    def __init__(self, batch_size, n_nodes,\n",
    "                 dim_hidden=1,\n",
    "                 activation='tanh',\n",
    "                 recurrent_activation='hard_sigmoid',\n",
    "                 **kwargs):\n",
    "        super(GRNN, self).__init__(**kwargs)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_nodes = n_nodes\n",
    "        self.dim_hidden = dim_hidden\n",
    "        \n",
    "        self.cells = []\n",
    "        for i in range(n_nodes):\n",
    "            cell = GRU(units=dim_hidden,\n",
    "                       activation=activation,\n",
    "                       recurrent_activation=recurrent_activation,\n",
    "                       return_state=True)\n",
    "            self.cells.append(cell)\n",
    "        self.h_state = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape = (T, N, D)\n",
    "        # h_state = (T, D, N)\n",
    "        input_shape = input_shape[0]\n",
    "        self.timesteps = input_shape[1]\n",
    "        self.dim_feature=input_shape[-1]\n",
    "        cell_input_shape = [self.timesteps, self.dim_feature]\n",
    "        for cell in self.cells:\n",
    "            cell.build(cell_input_shape)\n",
    "        self.h_state = K.zeros((self.batch_size, self.timesteps,\n",
    "                               self.dim_hidden, self.n_nodes))\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # output_shape = (B, N, D)\n",
    "        #input_shape = input_shape[0]\n",
    "        cell_input_shape = [input_shape[0], input_shape[1], input_shape[3]]\n",
    "        cell_output_shape = self.cells[0].compute_output_shape(cell_input_shape)\n",
    "        output_shape = cell_output_shape[0]\n",
    "        output_shape = K.expand_dims(output_shape, axis=1)\n",
    "        output_shape[1] = self.n_nodes\n",
    "        return output_shape\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        # A = (N, N)\n",
    "        O = K.zeros((self.batch_size, self.n_nodes, self.dim_feature))\n",
    "        H = K.zeros((self.batch_size, self.timesteps, self.dim_hidden, self.n_nodes))\n",
    "        \n",
    "        x_main = x[0]\n",
    "        A = x[1]\n",
    "\n",
    "        S = bmm(self.h_state, A, self.n_nodes) # S: (B, T, D, N)\n",
    "        #assert K.is_keras_tensor(S)\n",
    "    \n",
    "        for n in range(self.n_nodes):\n",
    "            cell = self.cells[n]\n",
    "            cell_output = cell.call(x_main[:, :, n, :],\n",
    "                    initial_state=[S[:, :, :, n]],\n",
    "                    training=training)\n",
    "            assert len(cell_output) == 2\n",
    "            O[:, n, :], H[:, :, :, n] = cell_output[0], cell_output[1]\n",
    "\n",
    "        if training:\n",
    "            self.h_state = H\n",
    "\n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.python.keras import backend as K\n",
    "#from tensorflow.python.keras.models import Model, Input\n",
    "#from tensorflow.python.keras.layers import GRU, GRUCell, Layer\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import GRU, GRUCell, Layer\n",
    "from keras.optimizers import adam\n",
    "\n",
    "def bmm(H, A, n_nodes):\n",
    "    current_shape = K.shape(H)\n",
    "    H = K.reshape(H, [-1, n_nodes])\n",
    "    M = K.dot(H, A)\n",
    "    return K.reshape(M, current_shape)\n",
    "\n",
    "def v_stack(x, axis=0):\n",
    "    x = [K.expand_dims(y, axis=axis) for y in x]\n",
    "    return K.concatenate(x, axis=axis)\n",
    "\n",
    "class GRNN(Layer):\n",
    "    def __init__(self, batch_size, n_nodes,\n",
    "                 dim_hidden=1,\n",
    "                 activation='tanh',\n",
    "                 recurrent_activation='hard_sigmoid',\n",
    "                 **kwargs):\n",
    "        super(GRNN, self).__init__(**kwargs)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_nodes = n_nodes\n",
    "        self.dim_hidden = dim_hidden\n",
    "        \n",
    "        self.cells = []\n",
    "        for i in range(n_nodes):\n",
    "            cell = GRU(units=dim_hidden,\n",
    "                       activation=activation,\n",
    "                       recurrent_activation=recurrent_activation,\n",
    "                       return_state=True)\n",
    "            self.cells.append(cell)\n",
    "        self.h_state = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape = (T, N, D)\n",
    "        # h_state = (T, D, N)\n",
    "        input_shape = input_shape[0]\n",
    "        self.timesteps = input_shape[1]\n",
    "        self.dim_feature=input_shape[-1]\n",
    "        cell_input_shape = (None, self.timesteps, self.dim_feature)\n",
    "        for cell in self.cells:\n",
    "            cell.build(cell_input_shape)\n",
    "        self.h_state = None\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # output_shape = (B, N, D)\n",
    "        input_shape = input_shape[0]\n",
    "        cell_input_shape = (input_shape[1], input_shape[3])\n",
    "        cell_output_shape = self.cells[0].compute_output_shape(cell_input_shape)\n",
    "        output_shape = cell_output_shape[0]\n",
    "        return (output_shape[0], self.n_nodes, output_shape[-1])\n",
    "    \n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (B, T, H, N)\n",
    "        # inputs : (B, T, N, D)\n",
    "        print('input_shape =', K.shape(inputs))\n",
    "        initial_state = K.zeros_like(inputs)  # (B, T, N, D)\n",
    "        initial_state = K.sum(initial_state, axis=-1)  # (B, T, N,)\n",
    "        initial_state = K.expand_dims(initial_state, axis=-2)  # (B, T, 1, N)\n",
    "        cell = self.cells[0].cell\n",
    "        if hasattr(cell.state_size, '__len__'):\n",
    "            return [K.tile(initial_state, [1, 1, dim, 1])\n",
    "                    for dim in cell.state_size]\n",
    "        else:\n",
    "            return K.tile(initial_state, [1, 1, cell.state_size, 1])\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        # A = (N, N)\n",
    "        O = K.zeros((self.batch_size, self.n_nodes, self.dim_feature))\n",
    "        H = K.zeros((self.batch_size, self.timesteps, self.dim_hidden, self.n_nodes))\n",
    "        \n",
    "        x_main = x[0]\n",
    "        print('x_main_shape =', x_main.shape)\n",
    "        A = x[1]\n",
    "\n",
    "        if self.h_state is None:\n",
    "            self.h_state = self.get_initial_state(x_main)\n",
    "        S = bmm(self.h_state, A, self.n_nodes) # S: (B, T, H, N)\n",
    "        print(S.shape)\n",
    "        assert S.shape.as_list() == [None, self.timesteps, self.dim_hidden, self.n_nodes]\n",
    "    \n",
    "        O_list = []\n",
    "        H_list = []\n",
    "        for n in range(self.n_nodes):\n",
    "            cell = self.cells[n]\n",
    "            x = x_main[:, :, n, :]\n",
    "            cell_output = cell.call(x_main[:, :, n, :],\n",
    "                    initial_state=[S[:, :, :, n]],\n",
    "                    training=training)\n",
    "            \n",
    "            O, H = cell_output[0], cell_output[1] #: H : (B, T, H)\n",
    "            O_list.append(K.expand_dims(O, axis=1))\n",
    "            H_list.append(K.expand_dims(H, axis=-1))\n",
    "        \n",
    "        O = K.concatenate(O_list, axis=1)\n",
    "        if training:\n",
    "            self.h_state = K.concatenate(H_list, axis=-1)\n",
    "\n",
    "        return O\n",
    "    \n",
    "        @property\n",
    "        def trainable_weights(self):\n",
    "            if not self.trainable:\n",
    "                return []\n",
    "            trainable_weights = []\n",
    "            for cell in self.cells:\n",
    "                if isinstance(cell, Layer):\n",
    "                    print('is layer')\n",
    "                    trainable_weights.append(cell.trainable_weights)\n",
    "            return trainable_weights\n",
    "\n",
    "        @property\n",
    "        def non_trainable_weights(self):\n",
    "            non_trainable_weights = []\n",
    "            for cell in self.cells:\n",
    "                if isinstance(cell, Layer):\n",
    "                    non_trainable_weights.append(cell.non_trainable_weights)\n",
    "            return non_trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(batch_size, timesteps, n_nodes, ndims, n_hiddens):\n",
    "    input_main = Input(shape=(timesteps, n_nodes, ndims))\n",
    "    input_aux = Input(shape=(n_nodes, n_nodes), name='A')\n",
    "    inputs = [input_main, input_aux]\n",
    "    \n",
    "    x = GRNN(batch_size, n_nodes, n_hiddens)(inputs)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(loss='mse', optimizer=adam(lr=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_main_shape = (?, 2, 3, 4)\n",
      "input_shape = Tensor(\"grnn_17/Shape:0\", shape=(4,), dtype=int32)\n",
      "(?, 2, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "#model = create_model(1, timesteps, n_points, n_hidden)\n",
    "timesteps = 2\n",
    "n_nodes = 3\n",
    "ndims = 4\n",
    "n_hidden = 5\n",
    "model = create_model(1, timesteps, n_nodes, ndims, n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.random.randn(10, timesteps, n_nodes, n_dims)\n",
    "data_y = np.random.randn(10, timesteps, n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(1, n_nodes, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 2, 3, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A (InputLayer)                  (None, 3, 3)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "grnn_17 (GRNN)                  (2, 3, 5)            0           input_17[0][0]                   \n",
      "                                                                 A[0][0]                          \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected grnn_14 to have shape (3, 5) but got array with shape (2, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-01bc80425ba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected grnn_14 to have shape (3, 5) but got array with shape (2, 5)"
     ]
    }
   ],
   "source": [
    "model.fit([data_x, a], data_y, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "val = np.random.random((3, 4, 5))\n",
    "var = K.variable(value=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.is_keras_tensor(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.resource_variable_ops.ResourceVariable"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype):\n",
    "    if inputs is not None:\n",
    "        batch_size = array_ops.shape(inputs)[0]\n",
    "        dtype = inputs.dtype\n",
    "    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_zero_filled_state(batch_size_tensor, state_size, dtype):\n",
    "    \"\"\"Generate a zero filled tensor with shape [batch_size, state_size].\"\"\"\n",
    "    if None in [batch_size_tensor, dtype]:\n",
    "        raise ValueError(\n",
    "            'batch_size and dtype cannot be None while constructing initial state: '\n",
    "            'batch_size={}, dtype={}'.format(batch_size_tensor, dtype))\n",
    "    '''\n",
    "    if _is_multiple_state(state_size):\n",
    "        states = []\n",
    "        for dims in state_size:\n",
    "            flat_dims = tensor_shape.as_shape(dims).as_list()\n",
    "            init_state_size = [batch_size_tensor] + flat_dims\n",
    "            init_state = array_ops.zeros(init_state_size, dtype=dtype)\n",
    "            states.append(init_state)\n",
    "        return states\n",
    "    '''\n",
    "    \n",
    "    flat_dims = tensor_shape.as_shape(state_size).as_list()\n",
    "    init_state_size = [batch_size_tensor] + flat_dims\n",
    "    return array_ops.zeros(init_state_size, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = GRUCell(units=2,\n",
    "               activation='tanh',\n",
    "               recurrent_activation='hard_sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.python.keras import backend as K\n",
    "#from tensorflow.python.keras.models import Model, Input\n",
    "#from tensorflow.python.keras.layers import GRU, GRUCell, Layer\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import GRU, GRUCell, Layer\n",
    "from keras.optimizers import adam\n",
    "\n",
    "def bmm(H, A, n_nodes):\n",
    "    current_shape = K.shape(H)\n",
    "    H = K.reshape(H, [-1, n_nodes])\n",
    "    M = K.dot(H, A)\n",
    "    return K.reshape(M, current_shape)\n",
    "\n",
    "class GRNN_1(Layer):\n",
    "    def __init__(self, batch_size, n_nodes,\n",
    "                 dim_hidden=1,\n",
    "                 activation='tanh',\n",
    "                 recurrent_activation='hard_sigmoid',\n",
    "                 **kwargs):\n",
    "        super(GRNN_1, self).__init__(**kwargs)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_nodes = n_nodes\n",
    "        self.dim_hidden = dim_hidden\n",
    "        \n",
    "        self.cells = []\n",
    "        for i in range(n_nodes):\n",
    "            cell = GRU(units=dim_hidden,\n",
    "                       activation=activation,\n",
    "                       recurrent_activation=recurrent_activation,\n",
    "                       return_state=True)\n",
    "            self.cells.append(cell)\n",
    "        self.h_state = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape = (T, N, D)\n",
    "        # h_state = (T, D, N)\n",
    "        #input_shape = input_shape[0]\n",
    "        self.timesteps = input_shape[1]\n",
    "        self.dim_feature=input_shape[-1]\n",
    "        cell_input_shape = (None, self.timesteps, self.dim_feature)\n",
    "        for cell in self.cells:\n",
    "            cell.build(cell_input_shape)\n",
    "        self.h_state = K.zeros((self.batch_size, self.timesteps,\n",
    "                               self.dim_hidden, self.n_nodes))\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # output_shape = (B, N, D)\n",
    "        #input_shape = input_shape[0]\n",
    "        cell_input_shape = (input_shape[1], input_shape[3])\n",
    "        print('ncells =', len(self.cells))\n",
    "        print('type cell =', type(self.cells[0]))\n",
    "        cell_output_shape = self.cells[0].compute_output_shape(cell_input_shape)\n",
    "        print('cell_output_shape =', cell_output_shape)\n",
    "        output_shape = cell_output_shape[0]\n",
    "        return (output_shape[0], self.n_nodes, output_shape[-1])\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        # A = (N, N)\n",
    "        O = K.zeros((self.batch_size, self.n_nodes, self.dim_feature))\n",
    "        H = K.zeros((self.batch_size, self.timesteps, self.dim_hidden, self.n_nodes))\n",
    "        \n",
    "        x_main = x[0]\n",
    "        #A = x[1]\n",
    "\n",
    "        #S = bmm(self.h_state, A, self.n_nodes) # S: (B, T, D, N)\n",
    "        #assert K.is_keras_tensor(S)\n",
    "    \n",
    "        O_list = []\n",
    "        H_list = []\n",
    "        for n in range(self.n_nodes):\n",
    "            cell = self.cells[n]\n",
    "            x = x_main[:, :, n, :]\n",
    "            #assert K.is_keras_tensor(x)\n",
    "            assert x.shape.as_list() == [None, self.timesteps, self.dim_feature]\n",
    "            cell_output = cell.call(x_main[:, :, n, :],\n",
    "                    #initial_state=[S[:, :, :, n]],\n",
    "                    training=training)\n",
    "            assert len(cell_output) == 2\n",
    "            \n",
    "            O, H = cell_output[0], cell_output[1]\n",
    "            O_list.append(K.expand_dims(O, axis=1))\n",
    "            H_list.append(K.expand_dims(H, axis=-1))\n",
    "        \n",
    "        O = K.concatenate(O_list, axis=1)\n",
    "        if training:\n",
    "            self.h_state = K.concatenate(H_list, axis=-1)\n",
    "\n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_1(batch_size, timesteps, n_nodes, ndims):\n",
    "    input_main = Input(shape=(timesteps, n_nodes, ndims))\n",
    "    inputs = [input_main]\n",
    "    \n",
    "    x = GRNN_1(batch_size, n_nodes, ndims)(inputs)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(loss='mse', optimizer=adam(lr=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape = (None, 2, 4)\n",
      "step_input_shape = (None, 4)\n",
      "step_input_shape = (None, 4)\n",
      "4\n",
      "kernel_shape = Tensor(\"grnn_1_12/Shape:0\", shape=(2,), dtype=int32)\n",
      "input_shape = (None, 2, 4)\n",
      "step_input_shape = (None, 4)\n",
      "step_input_shape = (None, 4)\n",
      "4\n",
      "kernel_shape = Tensor(\"grnn_1_12/Shape_1:0\", shape=(2,), dtype=int32)\n",
      "input_shape = (None, 2, 4)\n",
      "step_input_shape = (None, 4)\n",
      "step_input_shape = (None, 4)\n",
      "4\n",
      "kernel_shape = Tensor(\"grnn_1_12/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "input_call = Tensor(\"grnn_1_12/Shape_3:0\", shape=(3,), dtype=int32)\n",
      "input_call = Tensor(\"grnn_1_12/Shape_5:0\", shape=(3,), dtype=int32)\n",
      "input_call = Tensor(\"grnn_1_12/Shape_7:0\", shape=(3,), dtype=int32)\n",
      "ncells = 3\n",
      "type cell = <class 'keras.layers.recurrent.GRU'>\n",
      "cell_output_shape = [(2, 4), (2, 4)]\n"
     ]
    }
   ],
   "source": [
    "model_1 = create_model_1(1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(2), Dimension(3), Dimension(4)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape == tf.TensorShape([tf.Dimension(None), tf.Dimension(1), tf.Dimension(2), tf.Dimension(3), tf.Dimension(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.tensor_shape.TensorShape"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = tf.TensorShape([tf.Dimension(None), tf.Dimension(1), tf.Dimension(2), tf.Dimension(3), tf.Dimension(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.tensor_shape.TensorShape"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Test_GRNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
