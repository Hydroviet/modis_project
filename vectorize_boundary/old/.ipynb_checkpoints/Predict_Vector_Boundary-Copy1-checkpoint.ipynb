{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tensorflow.python.keras.models import Input, Sequential, Model\\nfrom tensorflow.python.keras.layers import Dense, Dropout, LSTM, Activation, Add\\nfrom tensorflow.python.keras.utils import Sequence\\nfrom tensorflow.python.keras import backend as K\\nfrom tensorflow.python.keras.optimizers import adam, SGD\\nfrom tensorflow.python.keras.callbacks import ReduceLROnPlateau\\nfrom tensorflow.python.keras.utils import plot_model\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "'''\n",
    "from tensorflow.python.keras.models import Input, Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM, Activation, Add\n",
    "from tensorflow.python.keras.utils import Sequence\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.optimizers import adam, SGD\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.python.keras.utils import plot_model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modis_utils.misc import cache_data, restore_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Input, Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, Add\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "from keras.optimizers import adam, SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = restore_data('cache/boundary_vectors_ALL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boundary_vectors = data[0]\n",
    "val_boundary_vectors = data[1]\n",
    "test_boundary_vectors = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_points = train_boundary_vectors.shape[1]\n",
    "n_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((438, 1024, 2), (138, 1024, 2), (138, 1024, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boundary_vectors.shape, val_boundary_vectors.shape, test_boundary_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, scaler, flatten=True):\n",
    "    old_shape = data.shape\n",
    "    data = data.reshape(old_shape[0], -1)\n",
    "    data = scaler.transform(data.astype(np.float))\n",
    "    if not flatten:\n",
    "        return data.reshape(old_shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(train_boundary_vectors.reshape(train_boundary_vectors.shape[0], -1))\n",
    "train_boundary_vectors_scale = transform(train_boundary_vectors, scaler, flatten=True)\n",
    "val_boundary_vectors_scale = transform(val_boundary_vectors, scaler, flatten=True)\n",
    "test_boundary_vectors_scale = transform(test_boundary_vectors, scaler, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "train_boundary_vectors_scale_1 = transform(train_boundary_vectors, scaler, flatten=False)\n",
    "val_boundary_vectors_scale_1 = transform(val_boundary_vectors, scaler, flatten=False)\n",
    "test_boundary_vectors_scale_1 = transform(test_boundary_vectors, scaler, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(boundary_vectors_scale, timesteps):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    for i in range(len(boundary_vectors_scale) - timesteps):\n",
    "        data_x = boundary_vectors_scale[i:(i+timesteps)]\n",
    "        data_y = boundary_vectors_scale[i + timesteps]\n",
    "        data_X.append(data_x)\n",
    "        data_Y.append(data_y)\n",
    "    return np.asarray(data_X), np.asarray(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 50\n",
    "train_X, train_Y = create_dataset(train_boundary_vectors_scale, timesteps)\n",
    "val_X, val_Y = create_dataset(np.concatenate(\n",
    "    [train_boundary_vectors_scale[-timesteps:], val_boundary_vectors_scale]),\n",
    "                              timesteps)\n",
    "test_X, test_Y = create_dataset(np.concatenate(\n",
    "    [val_boundary_vectors_scale[-timesteps:], test_boundary_vectors_scale]),\n",
    "                                timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 50\n",
    "train_X_1, train_Y_1 = create_dataset(train_boundary_vectors_scale_1, timesteps)\n",
    "val_X_1, val_Y_1 = create_dataset(np.concatenate(\n",
    "    [train_boundary_vectors_scale_1[-timesteps:], val_boundary_vectors_scale_1]),\n",
    "                              timesteps)\n",
    "test_X_1, test_Y_1 = create_dataset(np.concatenate(\n",
    "    [val_boundary_vectors_scale_1[-timesteps:], test_boundary_vectors_scale_1]),\n",
    "                                timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((388, 50, 2048),\n",
       " (388, 2048),\n",
       " (138, 50, 2048),\n",
       " (138, 2048),\n",
       " (138, 50, 2048),\n",
       " (138, 2048))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape, val_X.shape, val_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((388, 50, 1024, 2),\n",
       " (388, 1024, 2),\n",
       " (138, 50, 1024, 2),\n",
       " (138, 1024, 2),\n",
       " (138, 50, 1024, 2),\n",
       " (138, 1024, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_1.shape, train_Y_1.shape, val_X_1.shape, val_Y_1.shape, test_X_1.shape, test_Y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_(model):\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    model_plot = misc.imread('model.png')\n",
    "    plt.imshow(model_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_matrix(n_points_on_boundary):\n",
    "    def calc_arc_distance(a, b, n):\n",
    "        diff = np.abs(a-b)\n",
    "        if diff > n//2:\n",
    "            diff = n - diff\n",
    "        return diff\n",
    "    \n",
    "    n = n_points_on_boundary\n",
    "    mat = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mat[i,j] = calc_arc_distance(i, j, n)\n",
    "    return mat.astype(np.float32)\n",
    "\n",
    "def create_graph_matrix_1(n_points_on_boundary):\n",
    "    def calc_arc_distance(a, b, n):\n",
    "        diff = np.abs(a-b)\n",
    "        if diff > n//2:\n",
    "            diff = n - diff\n",
    "        return diff\n",
    "    \n",
    "    n = n_points_on_boundary\n",
    "    mat = np.zeros((2*n, 2*n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mat[i,j] = calc_arc_distance(i, j, n)\n",
    "    mat[n:2*n, n:2*n] = mat[:n, :n]\n",
    "    for i in range(n):\n",
    "        for j in range(n, 2*n):\n",
    "            mat[i,j] = mat[i, j - n]\n",
    "    mat[n:2*n, :n] = mat[:n, n:2*n]\n",
    "    return mat.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 2048), (1024, 1024))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = create_graph_matrix_1(1024)\n",
    "a_1 = create_graph_matrix(n_points)\n",
    "a.shape, a_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_dgl.layers import GraphLSTM, GraphConvLSTM, GraphConvLSTM_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(timesteps, n_points, mat=None):\n",
    "    #from keras.layers import Input\n",
    "    K.clear_session()\n",
    "    \n",
    "    if mat is None:\n",
    "        mat = create_graph_matrix_1(n_points)\n",
    "    if len(mat.shape) == 2:\n",
    "        mat = np.expand_dims(mat, axis=0)\n",
    "    \n",
    "    inputs = Input(shape=(timesteps, n_points, 2))\n",
    "    x = GraphConvLSTM(n_points, graph_conv_tensor=mat, return_sequences=True, activation='tanh')(inputs)\n",
    "    x = GraphConvLSTM(n_points, graph_conv_tensor=mat, return_sequences=True, activation='tanh')(x)\n",
    "    predict = GraphConvLSTM(n_points*2, graph_conv_tensor=mat, return_sequences=False, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=predict)\n",
    "    \n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(GraphConvLSTM(4, graph_conv_tensor=mat, return_sequences=True, activation='tanh',\n",
    "                            input_shape=(timesteps, n_points, 2)))\n",
    "    model.add(GraphConvLSTM(4, graph_conv_tensor=mat, return_sequences=True, activation='tanh'))\n",
    "    model.add(GraphConvLSTM(2, graph_conv_tensor=mat, return_sequences=False, activation='sigmoid'))\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(GraphConvLSTM_1(4, graph_conv_tensor=mat, return_sequences=True, activation='tanh',\n",
    "                              input_shape=(timesteps, n_points, 2)))\n",
    "    model.add(GraphConvLSTM_1(4, graph_conv_tensor=mat, return_sequences=True, activation='tanh'))\n",
    "    model.add(GraphConvLSTM_1(2, graph_conv_tensor=mat, return_sequences=False, activation='sigmoid'))\n",
    "    '''\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=adam(lr=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer graph_conv_lstm_1: expected shape=(None, None, 2048, 2), found shape=(None, 50, 1024, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bfa3972062e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-c4e7380d42ec>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(timesteps, n_points, mat)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConvLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_conv_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConvLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_conv_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConvLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_points\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_conv_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;31m# modify the input spec to include the state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    527\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                                     \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                                     str(x_shape))\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer graph_conv_lstm_1: expected shape=(None, None, 2048, 2), found shape=(None, 50, 1024, 2)"
     ]
    }
   ],
   "source": [
    "model = create_model(timesteps, n_points, mat=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "graph_conv_lstm_1 (GraphConv (None, 50, 1024, 4)       112       \n",
      "_________________________________________________________________\n",
      "graph_conv_lstm_2 (GraphConv (None, 50, 1024, 4)       144       \n",
      "_________________________________________________________________\n",
      "graph_conv_lstm_3 (GraphConv (None, 1024, 2)           56        \n",
      "=================================================================\n",
      "Total params: 312\n",
      "Trainable params: 312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'graph_conv_lstm_1/kernel:0' shape=(2, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'graph_conv_lstm_1/recurrent_kernel:0' shape=(4, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'graph_conv_lstm_1/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'graph_conv_lstm_2/kernel:0' shape=(4, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'graph_conv_lstm_2/recurrent_kernel:0' shape=(4, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'graph_conv_lstm_2/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'graph_conv_lstm_3/kernel:0' shape=(4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'graph_conv_lstm_3/recurrent_kernel:0' shape=(2, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'graph_conv_lstm_3/bias:0' shape=(8,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=0.00001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 388 samples, validate on 138 samples\n",
      "Epoch 1/20\n",
      "388/388 [==============================] - 23s 60ms/step - loss: 0.3413 - val_loss: 0.3314\n",
      "Epoch 2/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.3237 - val_loss: 0.3315\n",
      "Epoch 3/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.3237 - val_loss: 0.3315\n",
      "Epoch 4/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.3237 - val_loss: 0.3315\n",
      "Epoch 5/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.3237 - val_loss: 0.3315\n",
      "Epoch 6/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.3237 - val_loss: 0.3315\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
      "Epoch 7/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.3237 - val_loss: 0.3315\n",
      "Epoch 8/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.3237 - val_loss: 0.3315\n",
      "Epoch 9/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.3237 - val_loss: 0.3315\n",
      "Epoch 10/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.2988 - val_loss: 0.2016\n",
      "Epoch 11/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1923 - val_loss: 0.1960\n",
      "Epoch 12/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1890 - val_loss: 0.1953\n",
      "Epoch 13/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1887 - val_loss: 0.1953\n",
      "Epoch 14/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1886 - val_loss: 0.1953\n",
      "Epoch 15/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1886 - val_loss: 0.1953\n",
      "Epoch 16/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1886 - val_loss: 0.1953\n",
      "Epoch 17/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1886 - val_loss: 0.1953\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "Epoch 18/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1886 - val_loss: 0.1953\n",
      "Epoch 19/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1886 - val_loss: 0.1953\n",
      "Epoch 20/20\n",
      "388/388 [==============================] - 17s 43ms/step - loss: 0.1886 - val_loss: 0.1953\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y, epochs=20, validation_data=(val_X, val_Y),\n",
    "                    verbose=1, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
