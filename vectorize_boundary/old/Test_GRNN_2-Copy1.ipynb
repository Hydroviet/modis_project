{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9-Nn0CsF1L44",
    "outputId": "39830814-9386-4ff9-ebe5-497abc9c37e7"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('gdrive')\n",
    "    gdrive_dir = 'cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_sIeTMQ1JIa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exE_fQWg1JIh"
   },
   "outputs": [],
   "source": [
    "from modis_utils.misc import cache_data, restore_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5r9tSawW1JIl"
   },
   "outputs": [],
   "source": [
    "data = restore_data(os.path.join('cache', 'boundary_vectors_ALL.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cReEtZNI1JIn"
   },
   "outputs": [],
   "source": [
    "train_boundary_vectors = data[0]\n",
    "val_boundary_vectors = data[1]\n",
    "test_boundary_vectors = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Evr_F7S31JIq",
    "outputId": "a05d7af0-96f1-4324-b4e4-bb01f1e713e4"
   },
   "outputs": [],
   "source": [
    "n_points = train_boundary_vectors.shape[1]\n",
    "n_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kcNKTrpr1JIu",
    "outputId": "76513dc6-8445-4f9e-e3e5-0b69d32ae833"
   },
   "outputs": [],
   "source": [
    "train_boundary_vectors.shape, val_boundary_vectors.shape, test_boundary_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoC45MTR1JIy"
   },
   "outputs": [],
   "source": [
    "def transform(data, scaler):\n",
    "    old_shape = data.shape\n",
    "    data = data.reshape(old_shape[0], -1)\n",
    "    if scaler is not None:\n",
    "        data = scaler.transform(data.astype(np.float))\n",
    "    #return data.reshape(old_shape)\n",
    "    return data\n",
    "  \n",
    "def transform_standardize(data, mean, std):\n",
    "    old_shape = data.shape\n",
    "    data = data.reshape(old_shape[0], -1)\n",
    "    data = (data - mean)/std\n",
    "    return data.reshape(old_shape)\n",
    "    #return data\n",
    "    \n",
    "def find_mean_std(data):\n",
    "    old_shape = data.shape\n",
    "    data = data.reshape(old_shape[0], -1)\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    std[std == 0] = 1\n",
    "    #mean = mean.reshape(-1, old_shape[-1])\n",
    "    #std = std.reshape(-1, old_shape[-1])\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLqx4tD-1JI0"
   },
   "outputs": [],
   "source": [
    "scaler = None\n",
    "scale_data = False\n",
    "if scale_data:\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(train_boundary_vectors.reshape(train_boundary_vectors.shape[0], -1))\n",
    "    \n",
    "mean, std = find_mean_std(train_boundary_vectors)\n",
    "train_boundary_vectors_1 = transform_standardize(train_boundary_vectors, mean, std)\n",
    "val_boundary_vectors_1 = transform_standardize(val_boundary_vectors, mean, std)\n",
    "test_boundary_vectors_1 = transform_standardize(test_boundary_vectors, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZvotXRA1JI3"
   },
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "'''\n",
    "train_boundary_vectors_scale_1 = transform(train_boundary_vectors, scaler, flatten=False)\n",
    "val_boundary_vectors_scale_1 = transform(val_boundary_vectors, scaler, flatten=False)\n",
    "test_boundary_vectors_scale_1 = transform(test_boundary_vectors, scaler, flatten=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XLY_Cuit1JI5",
    "outputId": "2258351d-7359-4b75-81ef-8de5fe2e36a0"
   },
   "outputs": [],
   "source": [
    "train_boundary_vectors_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-u5aVh31JI9"
   },
   "outputs": [],
   "source": [
    "def create_dataset(boundary_vectors_scale, timesteps):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    for i in range(len(boundary_vectors_scale) - timesteps):\n",
    "        data_x = boundary_vectors_scale[i:(i+timesteps)]\n",
    "        data_y = boundary_vectors_scale[i + timesteps]\n",
    "        data_X.append(data_x)\n",
    "        data_Y.append(data_y)\n",
    "    return np.asarray(data_X), np.asarray(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvuWC_3k1JI_"
   },
   "outputs": [],
   "source": [
    "timesteps = 50\n",
    "train_X, train_Y = create_dataset(train_boundary_vectors_1, timesteps)\n",
    "val_X, val_Y = create_dataset(np.concatenate(\n",
    "    [train_boundary_vectors_1[-timesteps:], val_boundary_vectors_1]),\n",
    "                              timesteps)\n",
    "test_X, test_Y = create_dataset(np.concatenate(\n",
    "    [val_boundary_vectors_1[-timesteps:], test_boundary_vectors_1]),\n",
    "                                timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "CILpLtpU1JJF",
    "outputId": "2af30de8-0b8c-4186-ab0d-4d6ff99b25f5"
   },
   "outputs": [],
   "source": [
    "train_X.shape, train_Y.shape, val_X.shape, val_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBL1WZ0B1JJN"
   },
   "outputs": [],
   "source": [
    "def create_graph_matrix(n_points_on_boundary):\n",
    "    def calc_arc_distance(a, b, n):\n",
    "        diff = np.abs(a-b)\n",
    "        if diff > n//2:\n",
    "            diff = n - diff\n",
    "        return diff\n",
    "    \n",
    "    n = n_points_on_boundary\n",
    "    mat = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mat[i,j] = calc_arc_distance(i, j, n)\n",
    "    return mat.astype(np.float32)\n",
    "\n",
    "def create_graph_matrix_1(n_points_on_boundary):\n",
    "    def calc_arc_distance(a, b, n):\n",
    "        diff = np.abs(a-b)\n",
    "        if diff > n//2:\n",
    "            diff = n - diff\n",
    "        return diff\n",
    "    \n",
    "    n = n_points_on_boundary\n",
    "    mat = np.zeros((2*n, 2*n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mat[i,j] = calc_arc_distance(i, j, n)\n",
    "    mat[n:2*n, n:2*n] = mat[:n, :n]\n",
    "    for i in range(n):\n",
    "        for j in range(n, 2*n):\n",
    "            mat[i,j] = mat[i, j - n]\n",
    "    mat[n:2*n, :n] = mat[:n, n:2*n]\n",
    "    return mat.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A_HxgB4J1JJQ",
    "outputId": "25202c70-6c2c-4da8-f193-7fb60fc30dd0"
   },
   "outputs": [],
   "source": [
    "mat = create_graph_matrix(n_points)\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vm584opiCXWO"
   },
   "outputs": [],
   "source": [
    "A = np.divide(mat, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0rpImRf1JJc"
   },
   "outputs": [],
   "source": [
    "#from grnn.model_keras import GRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.optimizers import adam\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Layer, RNN, GRUCell, GRU\n",
    "from keras.layers import deserialize as deserialize_layer\n",
    "from keras import activations, initializers, regularizers, constraints\n",
    "\n",
    "def tf_print(tensor, message=None):\n",
    "    def print_message(x):\n",
    "        sys.stdout.write(message + \" %s\\n\" % x)\n",
    "        return x\n",
    "\n",
    "    prints = [tf.py_func(print_message, [tensor], tensor.dtype)]\n",
    "    with tf.control_dependencies(prints):\n",
    "        op = tensor + 1\n",
    "        op = tf.identity(op)\n",
    "    return op\n",
    "\n",
    "# GRNNCell\n",
    "class GRUCellKeepDim(GRUCell):\n",
    "    def __init__(self, n_dims, units,\n",
    "                 activation='tanh',\n",
    "                 recurrent_activation='hard_sigmoid',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 recurrent_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 recurrent_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 dropout=0.,\n",
    "                 recurrent_dropout=0.,\n",
    "                 implementation=1,\n",
    "                 reset_after=False,\n",
    "                 **kwargs):\n",
    "        super(GRUCellKeepDim, self).__init__(units, activation, recurrent_activation)\n",
    "        self.n_dims = n_dims\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.last_kernel = self.add_weight(shape=(self.units, self.n_dims),\n",
    "                                           name='last_kernel',\n",
    "                                           initializer=self.kernel_initializer,\n",
    "                                           regularizer=self.kernel_regularizer,\n",
    "                                           constraint=self.kernel_constraint)\n",
    "        super(GRUCellKeepDim, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs, states, training=None):\n",
    "        output, states = super(GRUCellKeepDim, self).call(inputs, states, training)\n",
    "        output = K.dot(output, self.last_kernel)\n",
    "        return output, states\n",
    "    \n",
    "class GRUKeepDim(GRU):\n",
    "    def __init__(self, n_dims, units,\n",
    "                 activation='tanh',\n",
    "                 recurrent_activation='hard_sigmoid',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 recurrent_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 recurrent_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 dropout=0.,\n",
    "                 recurrent_dropout=0.,\n",
    "                 implementation=1,\n",
    "                 return_sequences=False,\n",
    "                 return_state=False,\n",
    "                 go_backwards=False,\n",
    "                 stateful=False,\n",
    "                 unroll=False,\n",
    "                 reset_after=False,\n",
    "                 **kwargs):\n",
    "        if implementation == 0:\n",
    "            warnings.warn('`implementation=0` has been deprecated, '\n",
    "                          'and now defaults to `implementation=1`.'\n",
    "                          'Please update your layer call.')\n",
    "        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n",
    "            warnings.warn(\n",
    "                'RNN dropout is no longer supported with the Theano backend '\n",
    "                'due to technical limitations. '\n",
    "                'You can either set `dropout` and `recurrent_dropout` to 0, '\n",
    "                'or use the TensorFlow backend.')\n",
    "            dropout = 0.\n",
    "            recurrent_dropout = 0.\n",
    "\n",
    "        cell = GRUCellKeepDim(n_dims, units,\n",
    "                              activation=activation,\n",
    "                              recurrent_activation=recurrent_activation,\n",
    "                              use_bias=use_bias,\n",
    "                              kernel_initializer=kernel_initializer,\n",
    "                              recurrent_initializer=recurrent_initializer,\n",
    "                              bias_initializer=bias_initializer,\n",
    "                              kernel_regularizer=kernel_regularizer,\n",
    "                              recurrent_regularizer=recurrent_regularizer,\n",
    "                              bias_regularizer=bias_regularizer,\n",
    "                              kernel_constraint=kernel_constraint,\n",
    "                              recurrent_constraint=recurrent_constraint,\n",
    "                              bias_constraint=bias_constraint,\n",
    "                              dropout=dropout,\n",
    "                              recurrent_dropout=recurrent_dropout,\n",
    "                              implementation=implementation,\n",
    "                              reset_after=reset_after)\n",
    "        RNN.__init__(self, cell,\n",
    "                     return_sequences=return_sequences,\n",
    "                     return_state=return_state,\n",
    "                     go_backwards=go_backwards,\n",
    "                     stateful=stateful,\n",
    "                     unroll=unroll,\n",
    "                     **kwargs)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        if hasattr(self.cell.state_size, '__len__'):\n",
    "            state_size = self.cell.state_size\n",
    "        else:\n",
    "            state_size = [self.cell.state_size]\n",
    "        output_dim = self.cell.n_dims\n",
    "\n",
    "        if self.return_sequences:\n",
    "            output_shape = (input_shape[0], input_shape[1], output_dim)\n",
    "        else:\n",
    "            output_shape = (input_shape[0], output_dim)\n",
    "\n",
    "        if self.return_state:\n",
    "            state_shape = [(input_shape[0], dim) for dim in state_size]\n",
    "            return [output_shape] + state_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def call(self, inputs, mask=None, training=None, initial_state=None):\n",
    "        self.cell._dropout_mask = None\n",
    "        self.cell._recurrent_dropout_mask = None\n",
    "        return super(GRUKeepDim, self).call(inputs,\n",
    "                                             mask=mask,\n",
    "                                             training=training,\n",
    "                                             initial_state=initial_state)\n",
    "\n",
    "\n",
    "class GRNNCell(Layer):\n",
    "    def __init__(cells, **kwargs):\n",
    "        super(GRNNCell, self).__init__(**kwargs)\n",
    "        self.cells = cells\n",
    "        \n",
    "    def __init__(self, cells, **kwargs):\n",
    "        for cell in cells:\n",
    "            if not hasattr(cell, 'call'):\n",
    "                raise ValueError('All cells must have a `call` method. '\n",
    "                                 'received cells:', cells)\n",
    "            if not hasattr(cell, 'state_size'):\n",
    "                raise ValueError('All cells must have a '\n",
    "                                 '`state_size` attribute. '\n",
    "                                 'received cells:', cells)\n",
    "        self.cells = cells\n",
    "        super(GRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        state_size = []\n",
    "        for cell in self.cells:\n",
    "            if hasattr(cell.state_size, '__len__'):\n",
    "                state_size += list(cell.state_size)\n",
    "            else:\n",
    "                state_size.append(cell.state_size)\n",
    "        return tuple(state_size)\n",
    "\n",
    "    def call(self, inputs, states, constants=None, **kwargs):\n",
    "        # Recover per-cell states.\n",
    "        nested_states = []\n",
    "        for cell in self.cells:\n",
    "            if hasattr(cell.state_size, '__len__'):\n",
    "                nested_states.append(states[:len(cell.state_size)])\n",
    "                states = states[len(cell.state_size):]\n",
    "            else:\n",
    "                nested_states.append([states[0]])\n",
    "                states = states[1:]\n",
    "\n",
    "        # Call the cells in order and store the returned states.\n",
    "        new_nested_states = []\n",
    "        for cell, states in zip(self.cells, nested_states):\n",
    "            if has_arg(cell.call, 'constants'):\n",
    "                inputs, states = cell.call(inputs, states,\n",
    "                                           constants=constants,\n",
    "                                           **kwargs)\n",
    "            else:\n",
    "                inputs, states = cell.call(inputs, states, **kwargs)\n",
    "            new_nested_states.append(states)\n",
    "\n",
    "        # Format the new states as a flat list\n",
    "        # in reverse cell order.\n",
    "        states = []\n",
    "        for cell_states in new_nested_states:\n",
    "            states += cell_states\n",
    "        return inputs, states\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        timesteps = input_shape[1]\n",
    "        n_dims=input_shape[-1]\n",
    "        cell_input_shape = (None, timesteps, n_dims)\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                cell.build(cell_input_shape)\n",
    "        self.built = True\n",
    "\n",
    "    def get_config(self):\n",
    "        cells = []\n",
    "        for cell in self.cells:\n",
    "            cells.append({'class_name': cell.__class__.__name__,\n",
    "                          'config': cell.get_config()})\n",
    "        config = {'cells': cells}\n",
    "        base_config = super(GRNNCell, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        cells = []\n",
    "        for cell_config in config.pop('cells'):\n",
    "            cells.append(deserialize_layer(cell_config,\n",
    "                                           custom_objects=custom_objects))\n",
    "        return cls(cells, **config)\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        weights = []\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                weights += cell.trainable_weights\n",
    "        return weights\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        weights = []\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                weights += cell.non_trainable_weights\n",
    "        if not self.trainable:\n",
    "            trainable_weights = []\n",
    "            for cell in self.cells:\n",
    "                if isinstance(cell, Layer):\n",
    "                    trainable_weights += cell.trainable_weights\n",
    "            return trainable_weights + weights\n",
    "        return weights\n",
    "\n",
    "    def get_weights(self):\n",
    "        \"\"\"Retrieves the weights of the model.\n",
    "\n",
    "        # Returns\n",
    "            A flat list of Numpy arrays.\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                weights += cell.weights\n",
    "        return K.batch_get_value(weights)\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        \"\"\"Sets the weights of the model.\n",
    "\n",
    "        # Arguments\n",
    "            weights: A list of Numpy arrays with shapes and types matching\n",
    "                the output of `model.get_weights()`.\n",
    "        \"\"\"\n",
    "        tuples = []\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                num_param = len(cell.weights)\n",
    "                weights = weights[:num_param]\n",
    "                for sw, w in zip(cell.weights, weights):\n",
    "                    tuples.append((sw, w))\n",
    "                weights = weights[num_param:]\n",
    "        K.batch_set_value(tuples)\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        losses = []\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                cell_losses = cell.losses\n",
    "                losses += cell_losses\n",
    "        return losses\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        losses = []\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                cell_losses = cell.get_losses_for(inputs)\n",
    "                losses += cell_losses\n",
    "        return losses\n",
    "\n",
    "\n",
    "# GRNN\n",
    "class GRNN(Layer):\n",
    "    def __init__(self, n_nodes, n_dims, n_hiddens,\n",
    "                 activation='tanh',\n",
    "                 recurrent_activation='hard_sigmoid',\n",
    "                 return_sequences=False,\n",
    "                 **kwargs):\n",
    "        super(GRNN, self).__init__(**kwargs)\n",
    "        self.n_nodes = n_nodes\n",
    "        self.n_dims = n_dims\n",
    "        self.n_hiddens = n_hiddens\n",
    "        \n",
    "        cells = []\n",
    "        for i in range(n_nodes):\n",
    "            cell = GRUKeepDim(n_dims=n_dims, units=n_hiddens,\n",
    "                              activation=activation,\n",
    "                              recurrent_activation=recurrent_activation,\n",
    "                              return_state=True,\n",
    "                              return_sequences=return_sequences)\n",
    "            cells.append(cell)\n",
    "        \n",
    "        self.return_sequences = return_sequences\n",
    "        self.grnn_cell = GRNNCell(cells)\n",
    "        self.h_state = None\n",
    "        self.trainable = True\n",
    "        self._num_constants = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape[0] = (T, N, D)\n",
    "        # h_state = (T, D, N)\n",
    "        input_shape = input_shape[0]\n",
    "        self.timesteps = input_shape[1]\n",
    "        cell_input_shape = (None, self.timesteps, self.n_dims)\n",
    "        self.grnn_cell.build(input_shape)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # output_shape[0] = (N, D)\n",
    "        input_shape = input_shape[0]\n",
    "        cell_input_shape = (input_shape[0], input_shape[-1])\n",
    "        cell_output_shape = self.grnn_cell.cells[0].compute_output_shape(cell_input_shape)\n",
    "        output_shape = cell_output_shape[0]\n",
    "        if self.return_sequences:\n",
    "            return (None, output_shape[0], self.n_nodes, output_shape[-1]) # (T, N, H)\n",
    "        else:\n",
    "            return (None, self.n_nodes, output_shape[-1]) # (N, H)\n",
    "    \n",
    "    def get_initial_state(self, inputs):\n",
    "        # build an all-zero tensor of shape (B, T, H, N)\n",
    "        # inputs : (B, T, N, D)\n",
    "        initial_state = K.zeros_like(inputs)  # (B, T, N, D)\n",
    "        initial_state = K.sum(initial_state, axis=(1, -1))  # (B, N,)\n",
    "        initial_state = K.expand_dims(initial_state, axis=1)  # (B, 1, N)\n",
    "        cell = self.grnn_cell.cells[0].cell\n",
    "        if hasattr(cell.state_size, '__len__'):\n",
    "            return [K.tile(initial_state, [1, dim, 1])\n",
    "                    for dim in cell.state_size]\n",
    "        else:\n",
    "            return K.tile(initial_state, [1, cell.state_size, 1])\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        print('call')\n",
    "        # A = (B, N, N)\n",
    "        x_main = x[0]\n",
    "        A = x[1]\n",
    "\n",
    "        if self.h_state is None:\n",
    "            self.h_state = self.get_initial_state(x_main) # (B, H, N), (B, H, N) x (B, N, N) = (B, H, N)\n",
    "        S = K.batch_dot(self.h_state, A, axes=(2,1)) # S: (B, H, N)\n",
    "    \n",
    "        #TODO: add tf.while_loop\n",
    "        O_list = []\n",
    "        H_list = []\n",
    "        for n in range(self.n_nodes):\n",
    "            \n",
    "            n_tf = K.variable(n)\n",
    "            p = tf_print(n_tf, \"n = {}\".format(n))\n",
    "            result = p.eval(session=K.get_session())\n",
    "            \n",
    "            cell = self.grnn_cell.cells[n]\n",
    "            x_n = x_main[:, :, n, :]\n",
    "            S_n = S[:, :, n]\n",
    "            cell_output = cell.call(x_n,\n",
    "                    initial_state=[S_n],\n",
    "                    training=training)\n",
    "            \n",
    "            O = cell_output[0] # O = (B, H), return_sequences: (B, T, H)\n",
    "            H = cell_output[1] # H = (B, T, H)\n",
    "            \n",
    "            O_list.append(K.expand_dims(O, axis=-2))\n",
    "            H_list.append(K.expand_dims(H, axis=-1))\n",
    "        \n",
    "        O = K.concatenate(O_list, axis=-2)\n",
    "        if training:\n",
    "            self.h_state = K.concatenate(H_list, axis=-1)\n",
    "        return O\n",
    "    \n",
    "    @property\n",
    "    def states(self):\n",
    "        if self.h_state is None:\n",
    "            if isinstance(self.grnn_cell.state_size, int):\n",
    "                num_states = 1\n",
    "            else:\n",
    "                num_states = len(self.grnn_cell.state_size)\n",
    "            #return [None for _ in range(num_states)]\n",
    "            return None\n",
    "        return self.h_state\n",
    "\n",
    "    @states.setter\n",
    "    def states(self, h_state):\n",
    "        self.h_state = h_state\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'return_sequences': self.return_sequences}\n",
    "        if self._num_constants is not None:\n",
    "            config['num_constants'] = self._num_constants\n",
    "\n",
    "        cell_config = self.grnn_cell.get_config()\n",
    "        config['grnn_cell'] = {'class_name': self.grnn_cell.__class__.__name__,\n",
    "                               'config': cell_config}\n",
    "        base_config = super(GRNN, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, custom_objects=None):\n",
    "        cell = deserialize_layer(config.pop('grnn_cell'),\n",
    "                                 custom_objects=custom_objects)\n",
    "        num_constants = config.pop('num_constants', None)\n",
    "        layer = cls(cell, **config)\n",
    "        layer._num_constants = num_constants\n",
    "        return layer\n",
    "\n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        if isinstance(self.grnn_cell, Layer):\n",
    "            return self.grnn_cell.trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        if isinstance(self.grnn_cell, Layer):\n",
    "            if not self.trainable:\n",
    "                return self.grnn_cell.weights\n",
    "            return self.grnn_cell.non_trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def losses(self):\n",
    "        layer_losses = super(GRNN, self).losses\n",
    "        if isinstance(self.grnn_cell, Layer):\n",
    "            return self.grnn_cell.losses + layer_losses\n",
    "        return layer_losses\n",
    "\n",
    "    def get_losses_for(self, inputs=None):\n",
    "        if isinstance(self.grnn_cell, Layer):\n",
    "            cell_losses = self.grnn_cell.get_losses_for(inputs)\n",
    "            return cell_losses + super(GRNN, self).get_losses_for(inputs)\n",
    "        return super(GRNN, self).get_losses_for(inputs)\n",
    "    \n",
    "def bmm(x, A):\n",
    "    current_shape = K.shape(x)\n",
    "    x = K.reshape(x, (-1, current_shape[-1]))\n",
    "    M = K.dot(x, A)\n",
    "    return M.reshape(current_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.optimizers import adam\n",
    "from keras.models import Model, Input\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from grnn_keras import GRNN, GRNNCell, GRUKeepDim, GRUCellKeepDim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(timesteps, n_nodes, n_dims, n_hiddens, dropout=0., recurrent_dropout=0., cell_type='gru'):\n",
    "    K.clear_session()\n",
    "    input_main = Input(shape=(timesteps, n_nodes, n_dims))\n",
    "    input_aux = Input(shape=(n_nodes, n_nodes), name='A')\n",
    "    inputs = [input_main, input_aux]\n",
    "    \n",
    "    x = GRNN(n_nodes, n_dims, n_hiddens, keep_dims=False, return_sequences=True,\n",
    "             dropout=dropout, recurrent_dropout=recurrent_dropout, cell_type=cell_type)(inputs)\n",
    "    x = GRNN(n_nodes, n_hiddens, n_hiddens, keep_dims=False, return_sequences=True,\n",
    "             dropout=dropout, recurrent_dropout=recurrent_dropout, cell_type=cell_type)([x, input_aux])\n",
    "    x = GRNN(n_nodes, n_hiddens, n_dims, keep_dims=False, cell_type=cell_type,\n",
    "             dropout=dropout, recurrent_dropout=recurrent_dropout)([x, input_aux])\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(loss='mse', optimizer=adam(lr=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 6, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A (InputLayer)                  (None, 6, 6)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "grnn_1 (GRNN)                   (None, None, 6, 5)   900         input_1[0][0]                    \n",
      "                                                                 A[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "grnn_2 (GRNN)                   (None, None, 6, 5)   990         grnn_1[0][0]                     \n",
      "                                                                 A[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "grnn_3 (GRNN)                   (None, 6, 4)         720         grnn_2[0][0]                     \n",
      "                                                                 A[0][0]                          \n",
      "==================================================================================================\n",
      "Total params: 2,610\n",
      "Trainable params: 2,610\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = create_model(1, timesteps, n_points, n_hidden)\n",
    "batch_size = 10\n",
    "timesteps = 3\n",
    "n_nodes = 6\n",
    "n_dims = 4\n",
    "n_hiddens = 5\n",
    "dropout = 0.5\n",
    "recurrent_dropout = 0.5\n",
    "cell_type = 'gru'\n",
    "model = create_model(timesteps, n_nodes, n_dims, n_hiddens, dropout, recurrent_dropout, cell_type)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 6, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A (InputLayer)                  (None, 6, 6)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "grnn_1 (GRNN)                   (None, None, 6, 5)   1200        input_1[0][0]                    \n",
      "                                                                 A[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "grnn_2 (GRNN)                   (None, None, 6, 5)   1320        grnn_1[0][0]                     \n",
      "                                                                 A[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "grnn_3 (GRNN)                   (None, 6, 4)         960         grnn_2[0][0]                     \n",
      "                                                                 A[0][0]                          \n",
      "==================================================================================================\n",
      "Total params: 3,480\n",
      "Trainable params: 3,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = create_model(1, timesteps, n_points, n_hidden)\n",
    "batch_size = 10\n",
    "timesteps = 3\n",
    "n_nodes = 6\n",
    "n_dims = 4\n",
    "n_hiddens = 5\n",
    "dropout = 0.5\n",
    "recurrent_dropout = 0.5\n",
    "cell_type = 'lstm'\n",
    "model = create_model(timesteps, n_nodes, n_dims, n_hiddens, dropout, recurrent_dropout, 'lstm')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.random.randn(batch_size, timesteps, n_nodes, n_dims)\n",
    "data_y = np.random.randn(batch_size, n_nodes, n_dims)\n",
    "a = np.random.randn(batch_size, n_nodes, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1.0137\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 1.0115\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 1.0097\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 1.0080\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 1.0062\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 1.0044\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 1.0025\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 1.0006\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.9986\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 0.9966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d7820bb38>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([data_x, a], data_y, batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modis_utils.misc import cache_data, restore_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"grnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "weights = model.get_weights()\n",
    "cache_data(weights, \"grnn_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel1 = model_from_json(open('grnn.json', 'r').read(), custom_objects={'GRNN': GRNN,\\n                                                                        'GRNNCell': GRNNCell,\\n                                                                        'GRUKeepDim': GRUKeepDim,\\n                                                                        'GRUCellKeepDim': GRUCellKeepDim})\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model1 = model_from_json(open('grnn.json', 'r').read(), custom_objects={'GRNN': GRNN,\n",
    "                                                                        'GRNNCell': GRNNCell,\n",
    "                                                                        'GRUKeepDim': GRUKeepDim,\n",
    "                                                                        'GRUCellKeepDim': GRUCellKeepDim})\n",
    "'''                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 0 0.0\n",
      "n = 1 1.0\n",
      "n = 2 2.0\n",
      "n = 3 3.0\n",
      "n = 4 4.0\n",
      "n = 5 5.0\n"
     ]
    }
   ],
   "source": [
    "model1 = create_model(timesteps, n_nodes, n_dims, n_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (5, 15) for Tensor 'Placeholder_12:0', which has shape '(5, 4)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-0f3fe1d91779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grnn_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   2029\u001b[0m                 \u001b[0mtuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_param\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2375\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (5, 15) for Tensor 'Placeholder_12:0', which has shape '(5, 4)'"
     ]
    }
   ],
   "source": [
    "weights1 = restore_data('grnn_weights.h5')\n",
    "model1.set_weights(weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.random.randn(1, timesteps, n_nodes, n_dims)\n",
    "test_y = np.random.randn(1, n_nodes, n_dims)\n",
    "test_a = np.random.randn(1, n_nodes, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.8069762 , -0.27716914, -0.08066209, -0.2173638 ],\n",
       "        [-0.0471504 ,  0.3077119 , -0.50850165, -0.14706776],\n",
       "        [ 0.28091013,  0.1313437 , -0.18831247,  0.0615936 ],\n",
       "        [-0.09314417, -0.18319672, -0.4167047 ,  0.04447975],\n",
       "        [ 0.29835194,  0.44064412, -0.32845873,  0.87659216],\n",
       "        [-0.32595405, -0.24016304, -0.07882565,  0.17863667]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict([test_x, test_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate([test_x, test_a], test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Test_GRNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
