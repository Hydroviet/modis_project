{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modis_utils.misc import restore_data, cache_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../sequence_data/12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_file_names():\n",
    "    \"\"\"Returns the file names expected to exist in the input_dir.\"\"\"\n",
    "    file_names = {}\n",
    "    file_names['train'] = ['data_batch_%d' % i for i in range(1, 5)]\n",
    "    file_names['validation'] = ['data_batch_5']\n",
    "    file_names['eval'] = ['test_batch']\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tfrecord(input_files, output_file):\n",
    "    \"\"\"Converts a file to TFRecords.\"\"\"\n",
    "    print('Generating %s' % output_file)\n",
    "    with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "        for input_file in input_files:\n",
    "            inputs, labels, inputs_pw, labels_pw = restore_data(input_file)\n",
    "            num_entries_in_batch = len(inputs)\n",
    "            for i in range(num_entries_in_batch):\n",
    "                example = tf.train.Example(features=tf.train.Features(\n",
    "                    feature={\n",
    "                        'inputs': _float_feature(inputs[i].flatten().tolist()),\n",
    "                        'labels': _float_feature(labels[i].flatten().tolist())\n",
    "                    }))\n",
    "                record_writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ../sequence_data/12/val.tfrecords\n",
      "Done val!\n",
      "Generating ../sequence_data/12/test.tfrecords\n",
      "Done test!\n",
      "Generating ../sequence_data/12/train.tfrecords\n",
      "Done train!\n"
     ]
    }
   ],
   "source": [
    "for subset in ('val', 'test', 'train'):\n",
    "    input_dir = os.path.join(data_dir, subset)\n",
    "    input_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir)]\n",
    "    output_file = os.path.join(data_dir, subset + '.tfrecords')\n",
    "    try:\n",
    "        os.remove(output_file)\n",
    "    except OSError:\n",
    "        pass\n",
    "    # Convert to tf.train.Example and write the to TFRecords.\n",
    "    convert_to_tfrecord(input_files, output_file)\n",
    "    print('Done {}!'.format(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 15534, 'val': 1380, 'test': 2454}\n"
     ]
    }
   ],
   "source": [
    "n_examples = {'train': 0, 'val': 0, 'test': 0}\n",
    "for subset in ('train', 'val', 'test'):\n",
    "    n = 0\n",
    "    subset_data_dir = os.path.join(data_dir, subset)\n",
    "    for filename in os.listdir(subset_data_dir):\n",
    "        data = restore_data(os.path.join(subset_data_dir, filename))\n",
    "        n += len(data[0])\n",
    "    n_examples[subset] = n\n",
    "print(n_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_steps = 14\n",
    "out_steps = 12\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "DEPTH = 1\n",
    "\n",
    "\n",
    "class BCLDataSet(object):\n",
    "\n",
    "  def __init__(self, data_dir, subset='train', use_distortion=True):\n",
    "    self.data_dir = data_dir\n",
    "    self.subset = subset\n",
    "    self.use_distortion = use_distortion\n",
    "\n",
    "  def get_filenames(self):\n",
    "    if self.subset in ['train', 'val', 'test']:\n",
    "      return [os.path.join(self.data_dir, self.subset + '.tfrecords')]\n",
    "    else:\n",
    "      raise ValueError('Invalid data subset \"%s\"' % self.subset)\n",
    "\n",
    "  def parser(self, serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'inputs': tf.FixedLenFeature([in_steps * DEPTH * HEIGHT * WIDTH], tf.float32),\n",
    "            'labels': tf.FixedLenFeature([out_steps * DEPTH * HEIGHT * WIDTH], tf.float32),\n",
    "        })\n",
    "    #features['inputs'].set_shape([in_steps * DEPTH * HEIGHT * WIDTH])\n",
    "    #features['labels'].set_shape([out_steps * DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [in_steps * depth * height * width] to [in_steps, height, width, depth].\n",
    "    inputs = tf.reshape(features['inputs'], [in_steps, HEIGHT, WIDTH, DEPTH])\n",
    "    labels = tf.reshape(features['labels'], [out_steps, HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "  def make_batch(self, batch_size):\n",
    "    \"\"\"Read the images and labels from 'filenames'.\"\"\"\n",
    "    filenames = self.get_filenames()\n",
    "    # Repeat infinitely.\n",
    "    dataset = tf.data.TFRecordDataset(filenames).repeat()\n",
    "\n",
    "    # Parse records.\n",
    "    dataset = dataset.map(\n",
    "        self.parser, num_parallel_calls=batch_size)\n",
    "\n",
    "    # Potentially shuffle records.\n",
    "    if self.subset == 'train':\n",
    "      min_queue_examples = int(\n",
    "          BCLDataSet.num_examples_per_epoch(self.subset) * 0.4)\n",
    "      # Ensure that the capacity is sufficiently large to provide good random\n",
    "      # shuffling.\n",
    "      dataset = dataset.shuffle(buffer_size=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    inputs_batch, labels_batch = iterator.get_next()\n",
    "\n",
    "    return inputs_batch, labels_batch\n",
    "\n",
    "  @staticmethod\n",
    "  def num_examples_per_epoch(subset='train'):\n",
    "    if subset == 'train':\n",
    "      return 15534\n",
    "    elif subset == 'val':\n",
    "      return 1380\n",
    "    elif subset == 'test':\n",
    "      return 2454\n",
    "    else:\n",
    "      raise ValueError('Invalid data subset \"%s\"' % subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcl_dataset = BCLDataSet(data_dir, 'train', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features[inputs] = Tensor(\"ParseSingleExample/ParseSingleExample:0\", shape=(14336,), dtype=float32)\n",
      "features[labels] = Tensor(\"ParseSingleExample/ParseSingleExample:1\", shape=(12288,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batches = bcl_dataset.make_batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(12), Dimension(32), Dimension(32), Dimension(1)])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = batches[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'get_next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-185e9428aa34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'get_next'"
     ]
    }
   ],
   "source": [
    "c = batches[0].get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
